{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecd13e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_threads is set=4, n_jobs=-1 will be ignored. Current value: num_threads=4\n",
      "[LightGBM] GPU unavailable → CPU fallback\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# LG Aimers — Colab A100 Optimized Flat-path Submission Pipeline\n",
    "#  + ROOM 0-day 보정(평일/주말 분리) 포함\n",
    "#  + [마지막 전처리] 윈도우 내 양수 최댓값을 '둘째 큰 양수'로 클램프(주중/주말 분리)\n",
    "#     - 양수가 없으면 0으로 전처리\n",
    "#     - [주중 규칙 변경] 최댓값→둘째, 둘째→셋째로 클램프\n",
    "#  - 입력(루트): train.csv, TRAIN_weather.csv, TRAIN_room.csv\n",
    "#                TEST_00~09.csv, TEST_weather_00~09.csv, TEST_room_00~09.csv\n",
    "#                sample_submission.csv\n",
    "#  - 출력: submission_roomroom_1stclamp.csv\n",
    "#  - 최적화:\n",
    "#     * LightGBM GPU 자동 사용(가능 시) / 불가 시 CPU 폴백\n",
    "#     * num_threads=전체 코어, dtype float32 다운캐스팅\n",
    "#     * GPU 시 MultiOutputRegressor 병렬=1 (안정/안정성)\n",
    "# ============================================================\n",
    "\n",
    "import os, re, glob, unicodedata, warnings, math\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"mode.chained_assignment\", None)\n",
    "\n",
    "# -----------------------------\n",
    "# 고정 설정\n",
    "# -----------------------------\n",
    "SEED_BASE = 42\n",
    "np.random.seed(SEED_BASE)\n",
    "\n",
    "PREDICT, INPUT_WINDOW_DAYS = 7, 35\n",
    "DATE, KEY, TARGET = \"영업일자\",\"영업장명_메뉴명\",\"매출수량\"\n",
    "\n",
    "N_ESTIMATORS_FULL = 1200\n",
    "ANCHOR_K_FULL     = 7\n",
    "\n",
    "NON_SELLING_MIN_DAYS        = 14\n",
    "APPLY_METRIC_AWARE_WSMAPE   = True\n",
    "APPLY_METRIC_AWARE_WK_HOLOV = True\n",
    "FORCE_ACTIVE_MIN1           = True\n",
    "FORCE_GLOBAL_MIN1           = True\n",
    "\n",
    "CATEGORICAL_COLS = [\"key_encoded\",\"month\",\"dayofweek\"]\n",
    "\n",
    "# Tweedie p 앙상블 (CV 생략 → 균등 가중치)\n",
    "P_LIST = [1.1, 1.2, 1.3, 1.4]\n",
    "P_WEIGHTS = {p: 1.0/len(P_LIST) for p in P_LIST}\n",
    "\n",
    "# 제출 후처리 라운딩 임계치\n",
    "BEST_THR = 0.130\n",
    "\n",
    "NUM_THREADS = os.cpu_count() or 8  # 코랩 VM에 맞게 자동\n",
    "USE_GPU_AUTO = True                # GPU 자동 감지 시도\n",
    "\n",
    "# -----------------------------\n",
    "# 유틸/헬퍼\n",
    "# -----------------------------\n",
    "def to_datetime_norm(s):\n",
    "\treturn pd.to_datetime(s, errors=\"coerce\").dt.normalize()\n",
    "\n",
    "def _read_csv_robust(p):\n",
    "\ttry:\n",
    "\t\treturn pd.read_csv(p)\n",
    "\texcept UnicodeDecodeError:\n",
    "\t\treturn pd.read_csv(p, encoding=\"cp949\")\n",
    "\n",
    "def round_nonneg(pred, thr):\n",
    "\tpred = np.maximum(pred, 0.0)\n",
    "\tfrac = pred - np.floor(pred)\n",
    "\tout  = np.where(frac >= thr, np.floor(pred)+1, np.floor(pred))\n",
    "\treturn np.maximum(out, 0.0)\n",
    "\n",
    "def downcast_float32(df, exclude_cols=()):\n",
    "\tx = df.copy()\n",
    "\tfor c in x.columns:\n",
    "\t\tif c in exclude_cols:\n",
    "\t\t\tcontinue\n",
    "\t\tif pd.api.types.is_float_dtype(x[c]):\n",
    "\t\t\tx[c] = x[c].astype(np.float32)\n",
    "\t\telif pd.api.types.is_integer_dtype(x[c]) and x[c].isna().sum()==0:\n",
    "\t\t\tpass\n",
    "\treturn x\n",
    "\n",
    "def lightgbm_gpu_available():\n",
    "\tif not USE_GPU_AUTO:\n",
    "\t\treturn False\n",
    "\ttry:\n",
    "\t\tX = np.random.RandomState(0).randn(128, 8).astype(np.float32)\n",
    "\t\ty = (np.random.RandomState(1).rand(128) * 10).astype(np.float32)\n",
    "\t\tmdl = lgb.LGBMRegressor(\n",
    "\t\t\tn_estimators=5, objective=\"tweedie\", tweedie_variance_power=1.2,\n",
    "\t\t\tdevice=\"gpu\", gpu_platform_id=0, gpu_device_id=0,\n",
    "\t\t\tnum_threads=min(4, NUM_THREADS), verbose=-1\n",
    "\t\t)\n",
    "\t\tmdl.fit(X, y)\n",
    "\t\t_ = mdl.predict(X[:4])\n",
    "\t\treturn True\n",
    "\texcept Exception:\n",
    "\t\treturn False\n",
    "\n",
    "# -----------------------------\n",
    "# 디바이스 결정\n",
    "# -----------------------------\n",
    "GPU_OK = lightgbm_gpu_available()\n",
    "if GPU_OK:\n",
    "\tLGB_DEVICE_KW = dict(device=\"gpu\", gpu_platform_id=0, gpu_device_id=0)\n",
    "\tMOR_N_JOBS = 1     # GPU일 때 타깃 병렬을 1로(안정성/메모리)\n",
    "\tprint(\"[LightGBM] GPU enabled\")\n",
    "else:\n",
    "\tLGB_DEVICE_KW = dict()  # CPU\n",
    "\tMOR_N_JOBS = -1         # CPU 최대 병렬\n",
    "\tprint(\"[LightGBM] GPU unavailable → CPU fallback\")\n",
    "\n",
    "# -----------------------------\n",
    "# 0) ROOM 보정 유틸\n",
    "# -----------------------------\n",
    "def _canon(s):\n",
    "\treturn re.sub(r\"\\s+\",\"\", unicodedata.normalize(\"NFKC\", str(s).replace(\"\\ufeff\",\"\").replace(\"\\xa0\",\" \").strip()).lower()).replace(\"_\",\"\").replace(\"-\",\"\")\n",
    "\n",
    "def load_room_flags(path_room):\n",
    "\t\"\"\"\n",
    "\troom CSV → 날짜별 'room_all_zero' 플래그(DataFrame[DATE, room_all_zero]).\n",
    "\t판정 기준: 그 날짜의 '모든 객실 컬럼 합계' == 0  → 1, else 0 (엄격)\n",
    "\t\"\"\"\n",
    "\tif not os.path.exists(path_room):\n",
    "\t\treturn pd.DataFrame({DATE: pd.to_datetime([]), \"room_all_zero\": []})\n",
    "\tdf = _read_csv_robust(path_room)\n",
    "\tcmap = {c:_canon(c) for c in df.columns}\n",
    "\tdate_col = next((c for c in df.columns if cmap[c] in {_canon(\"영업일자\"), _canon(\"일자\"), _canon(\"날짜\"), _canon(\"date\")}), None)\n",
    "\tif date_col != DATE:\n",
    "\t\tdf = df.rename(columns={date_col: DATE})\n",
    "\tdf[DATE] = to_datetime_norm(df[DATE])\n",
    "\n",
    "\tnum_cols = [c for c in df.columns if c != DATE]\n",
    "\tfor c in num_cols:\n",
    "\t\tif not pd.api.types.is_numeric_dtype(df[c]):\n",
    "\t\t\tdf[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\tday_sum = df.groupby(DATE)[num_cols].sum(min_count=1)\n",
    "\tflag = (day_sum.fillna(0).sum(axis=1) == 0).astype(int).rename(\"room_all_zero\").reset_index()\n",
    "\treturn flag\n",
    "\n",
    "def apply_room_zero_fix(df_in, room_flags, window=28, min_obs=2):\n",
    "\t\"\"\"\n",
    "\tROOM 전처리:\n",
    "\t  - room_flags의 room_all_zero==1 인 날짜에 한하여,\n",
    "\t\t해당 날짜의 모든 메뉴 매출을 '평상시 값'으로 대체\n",
    "\t  - 평상시 값 = (같은 주중/주말) & room_all_zero==0 & 과거(<t) 관측의 최근 window개 중앙값\n",
    "\t\t* 대체값 산출 불가 시 → 과거 전체(room_all_zero==0) 중앙값\n",
    "\t\t* 그래도 없으면 → 원값 유지\n",
    "\t\"\"\"\n",
    "\tif room_flags is None or room_flags.empty:\n",
    "\t\treturn df_in.copy()\n",
    "\n",
    "\tdf = df_in.merge(room_flags, on=DATE, how=\"left\")\n",
    "\tdf[\"room_all_zero\"] = df[\"room_all_zero\"].fillna(0).astype(int)\n",
    "\tdf[\"is_weekend\"] = (df[DATE].dt.dayofweek >= 5).astype(int)\n",
    "\n",
    "\touts = []\n",
    "\tfor k, g in df.groupby(KEY, sort=False):\n",
    "\t\tg = g.sort_values(DATE).copy()\n",
    "\t\tidxs = g.index[g[\"room_all_zero\"]==1].tolist()\n",
    "\t\tfor idx in idxs:\n",
    "\t\t\td = g.at[idx, DATE]\n",
    "\t\t\tw = int(g.at[idx, \"is_weekend\"])\n",
    "\t\t\tpast = g[(g[DATE] < d) & (g[\"is_weekend\"]==w) & (g[\"room_all_zero\"]==0)]\n",
    "\t\t\tcand = past[TARGET].dropna().astype(float).values\n",
    "\t\t\tif cand.size < min_obs:\n",
    "\t\t\t\tpast_any = g[(g[DATE] < d) & (g[\"room_all_zero\"]==0)]\n",
    "\t\t\t\tcand = past_any[TARGET].dropna().astype(float).values\n",
    "\t\t\tif cand.size >= min_obs:\n",
    "\t\t\t\tval = float(np.median(cand[-window:]))\n",
    "\t\t\t\tg.at[idx, TARGET] = max(0.0, val)\n",
    "\t\touts.append(g.drop(columns=[\"is_weekend\",\"room_all_zero\"]))\n",
    "\tout = pd.concat(outs, axis=0).sort_values([KEY, DATE]).reset_index(drop=True)\n",
    "\treturn out\n",
    "\n",
    "# -----------------------------\n",
    "# (NEW) 마지막 단계 전처리: 최댓값→둘째 큰 양수로 클램프(주중/주말 분리)\n",
    "#        - 윈도우(df_in)에 양수가 없으면 0으로 처리\n",
    "#        - [주중] 최댓값→둘째, 둘째→셋째로 추가 클램프\n",
    "# -----------------------------\n",
    "def clamp_max_to_second_by_weekpart(df_in, date_col=DATE, key_col=KEY, target_col=TARGET):\n",
    "\tdf = df_in.copy()\n",
    "\tdf[\"_is_weekend_\"] = (df[date_col].dt.dayofweek >= 5).astype(int)\n",
    "\n",
    "\touts = []\n",
    "\tfor (k, we), g in df.groupby([key_col, \"_is_weekend_\"], sort=False):\n",
    "\t\tvals = g[target_col].astype(float).values\n",
    "\t\tpos_unique = np.unique(vals[vals > 0])\n",
    "\n",
    "\t\tif pos_unique.size == 0:\n",
    "\t\t\tg[target_col] = 0.0\n",
    "\t\telse:\n",
    "\t\t\tif we == 1:\n",
    "\t\t\t\t# 주말: 기존 로직 유지 — 최댓값을 둘째 값으로 클램프\n",
    "\t\t\t\tif pos_unique.size >= 2:\n",
    "\t\t\t\t\tlargest, second = pos_unique[-1], pos_unique[-2]\n",
    "\t\t\t\t\tmask1 = (g[target_col] == largest)\n",
    "\t\t\t\t\tif mask1.any():\n",
    "\t\t\t\t\t\tg.loc[mask1, target_col] = np.minimum(g.loc[mask1, target_col].astype(float), float(second))\n",
    "\t\t\telse:\n",
    "\t\t\t\t# 주중: 최댓값→둘째, 그리고 둘째→셋째\n",
    "\t\t\t\tif pos_unique.size >= 2:\n",
    "\t\t\t\t\tlargest, second = pos_unique[-1], pos_unique[-2]\n",
    "\t\t\t\t\tmask1 = (g[target_col] == largest)\n",
    "\t\t\t\t\tif mask1.any():\n",
    "\t\t\t\t\t\tg.loc[mask1, target_col] = np.minimum(g.loc[mask1, target_col].astype(float), float(second))\n",
    "\t\t\t\tif pos_unique.size >= 3:\n",
    "\t\t\t\t\tthird = pos_unique[-3]\n",
    "\t\t\t\t\tmask2 = (g[target_col] == second)\n",
    "\t\t\t\t\tif mask2.any():\n",
    "\t\t\t\t\t\tg.loc[mask2, target_col] = np.minimum(g.loc[mask2, target_col].astype(float), float(third))\n",
    "\n",
    "\t\touts.append(g.drop(columns=[\"_is_weekend_\"]))\n",
    "\tout = pd.concat(outs, axis=0).sort_values([key_col, date_col]).reset_index(drop=True)\n",
    "\treturn out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84893148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] (88844, 3) keys= 167 기간: 2023-01-01 → 2024-06-15\n",
      "HOL_WEEKDAY_SET size: 39\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 1) train 로드 & 표준화\n",
    "# -----------------------------\n",
    "train = _read_csv_robust(\"train.csv\")\n",
    "\n",
    "orig = list(train.columns)\n",
    "cmap = {c:_canon(c) for c in orig}\n",
    "date_alias   = {_canon(x) for x in [\"영업일자\",\"일자\",\"날짜\",\"date\"]}\n",
    "key_single   = {_canon(x) for x in [\"영업장명_메뉴명\",\"영업장명메뉴명\",\"key\",\"메뉴키\"]}\n",
    "store_alias  = {_canon(x) for x in [\"영업장명\",\"매장명\",\"지점명\",\"점포명\",\"매장\",\"영업장\"]}\n",
    "menu_alias   = {_canon(x) for x in [\"메뉴명\",\"상품명\",\"제품명\",\"메뉴\"]}\n",
    "targ_alias   = {_canon(x) for x in [\"매출수량\",\"판매수량\",\"수량\",\"qty\",\"판매량\"]}\n",
    "\n",
    "date_col   = next((c for c in orig if cmap[c] in date_alias), None)\n",
    "target_col = next((c for c in orig if cmap[c] in targ_alias), None)\n",
    "key_col    = next((c for c in orig if cmap[c] in key_single), None)\n",
    "\n",
    "if key_col is None:\n",
    "\tstore_col = next((c for c in orig if cmap[c] in store_alias), None)\n",
    "\tmenu_col  = next((c for c in orig if cmap[c] in menu_alias ), None)\n",
    "\ttrain[KEY] = train[store_col].astype(str).str.strip() + \"_\" + train[menu_col].astype(str).str.strip()\n",
    "else:\n",
    "\tif key_col != KEY: train = train.rename(columns={key_col:KEY})\n",
    "if date_col != DATE:     train = train.rename(columns={date_col:DATE})\n",
    "if target_col != TARGET: train = train.rename(columns={target_col:TARGET})\n",
    "\n",
    "train[DATE]   = to_datetime_norm(train[DATE])\n",
    "train[TARGET] = pd.to_numeric(train[TARGET], errors=\"coerce\").clip(lower=0)\n",
    "\n",
    "print(\"[train]\", train.shape, \"keys=\", train[KEY].nunique(), \"기간:\", train[DATE].min().date(), \"→\", train[DATE].max().date())\n",
    "\n",
    "# -----------------------------\n",
    "# 2) 날씨(학습) 로드 & 일단위 변환\n",
    "# -----------------------------\n",
    "weather_m = _read_csv_robust(\"TRAIN_weather.csv\")\n",
    "w = weather_m.rename(columns={\"일시\": DATE}).copy()\n",
    "w[DATE] = to_datetime_norm(w[DATE])\n",
    "col_tmax = next(c for c in w.columns if (\"최고\" in c and \"기온\" in c))\n",
    "col_tavg = next(c for c in w.columns if (\"평균\" in c and \"기온\" in c))\n",
    "w_day = (w[[DATE, col_tmax, col_tavg]]\n",
    "\t\t .groupby(DATE, as_index=False).mean(numeric_only=True)\n",
    "\t\t .rename(columns={col_tmax:\"wx_tmax\", col_tavg:\"wx_tavg\"}))\n",
    "\n",
    "# -----------------------------\n",
    "# 3) 테스트 파일/범위, 공휴일 세트\n",
    "# -----------------------------\n",
    "test_files = sorted([p for p in glob.glob(\"test/TEST_*.csv\")\n",
    "\t\t\t\t\t if re.fullmatch(r\"TEST_\\d{2}\\.csv\", os.path.basename(p))])\n",
    "\n",
    "test_list = []\n",
    "for p in test_files:\n",
    "\tt = _read_csv_robust(p)\n",
    "\tif DATE in t.columns:\n",
    "\t\tt[DATE] = to_datetime_norm(t[DATE])\n",
    "\ttest_list.append(t)\n",
    "\n",
    "dmin = min([train[DATE].min()] + [t[DATE].min() for t in test_list if DATE in t.columns])\n",
    "dmax = max([train[DATE].max()] + [t[DATE].max() for t in test_list if DATE in t.columns]) + pd.Timedelta(days=PREDICT+14)\n",
    "\n",
    "manual_days = pd.to_datetime([\n",
    "\t\"2023-01-23\",\"2023-01-24\",\"2023-03-01\",\"2023-05-05\",\"2023-05-29\",\"2023-06-06\",\"2023-08-15\",\n",
    "\t\"2023-09-28\",\"2023-09-29\",\"2023-10-02\",\"2023-10-03\",\"2023-10-09\",\"2023-12-25\",\n",
    "\t\"2024-01-01\",\"2024-02-09\",\"2024-02-12\",\"2024-03-01\",\"2024-04-10\",\"2024-05-06\",\"2024-05-15\",\n",
    "\t\"2024-06-06\",\"2024-08-15\",\"2024-09-16\",\"2024-09-17\",\"2024-09-18\",\"2024-10-01\",\"2024-10-03\",\"2024-10-09\",\"2024-12-25\",\n",
    "\t\"2025-01-01\",\"2025-01-27\",\"2025-01-28\",\"2025-01-29\",\"2025-01-30\",\"2025-03-03\",\n",
    "\t\"2025-05-05\",\"2025-05-06\",\"2025-06-03\",\"2025-06-06\",\"2025-08-15\",\"2025-10-03\",\"2025-10-09\",\"2025-12-25\",\n",
    "\t\"2026-01-01\"\n",
    "]).normalize()\n",
    "\n",
    "try:\n",
    "\timport holidays as _hol\n",
    "\tyears = sorted({d.year for d in pd.date_range(dmin, dmax, freq=\"D\")})\n",
    "\tkr = _hol.KR(years=years)\n",
    "\thol = pd.DatetimeIndex([pd.Timestamp(k) for k in kr]).normalize()\n",
    "\thol = pd.DatetimeIndex(sorted(set(hol) | set(manual_days)))\n",
    "except Exception:\n",
    "\thol = pd.DatetimeIndex(sorted(set(manual_days)))\n",
    "hol = hol[(hol>=dmin) & (hol<=dmax)]\n",
    "HOL_WEEKDAY_SET = set(hol[hol.dayofweek<5])\n",
    "print(\"HOL_WEEKDAY_SET size:\", len(HOL_WEEKDAY_SET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08c512af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hwadam meta (by DATE) ---\n",
    "hwadam = _read_csv_robust(\"TRAIN_hwadam.csv\").rename(columns={\"영업일자\": DATE})\n",
    "hwadam[DATE] = to_datetime_norm(hwadam[DATE])\n",
    "for c in [\"화담숲\",\"화담채\",\"모노레일\"]:\n",
    "\tif c in hwadam.columns:\n",
    "\t\thwadam[c] = pd.to_numeric(hwadam[c], errors=\"coerce\").fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70a6f77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_STORES = {\"화담숲주막\",\"화담숲카페\"}   # 조건 적용 대상 업장\n",
    "\n",
    "# --- hwadam 공통 merge ---\n",
    "hwadam = _read_csv_robust(\"TRAIN_hwadam.csv\").rename(columns={\"영업일자\": DATE})\n",
    "hwadam[DATE] = to_datetime_norm(hwadam[DATE])\n",
    "for c in [\"화담숲\",\"화담채\",\"모노레일\"]:\n",
    "    if c in hwadam.columns:\n",
    "        hwadam[c] = pd.to_numeric(hwadam[c], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "TARGET_STORES = {\"화담숲주막\",\"화담숲카페\"}\n",
    "\n",
    "# ✅ 이것만 남기고,\n",
    "def add_hwadam_feats(df_in, hw_day):\n",
    "    df = df_in.merge(hw_day[[DATE,\"화담숲\",\"화담채\",\"모노레일\"]], on=DATE, how=\"left\")\n",
    "    store = df[KEY].astype(str).str.rsplit(\"_\", n=1).str[0]\n",
    "    mask  = store.isin(TARGET_STORES)\n",
    "    df[\"hw_forest\"] = 0.0; df[\"hw_chae\"] = 0.0; df[\"hw_mono\"] = 0.0\n",
    "    df.loc[mask,\"hw_forest\"] = pd.to_numeric(df.loc[mask,\"화담숲\"],  errors=\"coerce\").fillna(0.0)\n",
    "    df.loc[mask,\"hw_chae\"]   = pd.to_numeric(df.loc[mask,\"화담채\"],  errors=\"coerce\").fillna(0.0)\n",
    "    df.loc[mask,\"hw_mono\"]   = pd.to_numeric(df.loc[mask,\"모노레일\"], errors=\"coerce\").fillna(0.0)\n",
    "    return df.drop(columns=[c for c in [\"화담숲\",\"화담채\",\"모노레일\"] if c in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8596510c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train_pre] (88844, 3) 기간: 2023-01-01 → 2024-06-15\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 4) 학습측 안전 전처리(평일 공휴일 급등 완화)\n",
    "# -----------------------------\n",
    "x = train.copy().sort_values([KEY, DATE]).reset_index(drop=True)\n",
    "x[\"dow\"] = x[DATE].dt.dayofweek\n",
    "x[\"is_nonhol_weekday\"] = ((x[\"dow\"]<5) & (~x[DATE].isin(HOL_WEEKDAY_SET))).astype(int)\n",
    "x[\"is_hol_wk\"]         = (x[DATE].isin(HOL_WEEKDAY_SET)).astype(int)\n",
    "x[\"__val__\"] = x[TARGET].astype(float)\n",
    "\n",
    "outs = []\n",
    "for k, g in x.groupby(KEY, sort=False):\n",
    "\tg = g.copy()\n",
    "\tg[\"med_wd_dow\"] = np.nan\n",
    "\tfor d in range(5):\n",
    "\t\tidx = (g[\"dow\"]==d) & (g[\"is_nonhol_weekday\"]==1)\n",
    "\t\ts = g.loc[idx,\"__val__\"]\n",
    "\t\tmed = s.shift(1).rolling(window=4, min_periods=2).median()\n",
    "\t\tg.loc[idx,\"med_wd_dow\"] = med.values\n",
    "\tthr_up = (1.0+0.25)*g[\"med_wd_dow\"]\n",
    "\tadj = ((g[\"is_hol_wk\"]==1)&np.isfinite(g[\"med_wd_dow\"])&(g[\"__val__\"]>thr_up))\n",
    "\tg.loc[adj,\"__val__\"] = np.maximum(0.0, np.round((1.0+0.10)*g.loc[adj,\"med_wd_dow\"]))\n",
    "\tg = g.drop(columns=[\"med_wd_dow\"])\n",
    "\touts.append(g)\n",
    "\n",
    "train_pre = pd.concat(outs, axis=0).drop(columns=[\"dow\",\"is_nonhol_weekday\",\"is_hol_wk\"])\n",
    "train_pre[TARGET] = train_pre[\"__val__\"].astype(float).clip(lower=0)\n",
    "train_pre = train_pre.drop(columns=\"__val__\").sort_values([KEY, DATE]).reset_index(drop=True)\n",
    "\n",
    "print(\"[train_pre]\", train_pre.shape, \"기간:\", train_pre[DATE].min().date(), \"→\", train_pre[DATE].max().date())\n",
    "\n",
    "# 학습 데이터에 날씨 결합\n",
    "train_pre = train_pre.merge(w_day, on=DATE, how=\"left\")\n",
    "train_pre = add_hwadam_feats(train_pre, hwadam)\n",
    "\n",
    "# -----------------------------\n",
    "# 4.5) ROOM 0-day 보정 (TRAIN)\n",
    "# -----------------------------\n",
    "room_train_flags = load_room_flags(\"TRAIN_room.csv\")\n",
    "train_pre = apply_room_zero_fix(train_pre, room_train_flags, window=28, min_obs=2)\n",
    "\n",
    "# -----------------------------\n",
    "# 4.9) [마지막 전처리] 최댓값→둘째 큰 양수 클램프(주중/주말 분리, 양수 없으면 0)\n",
    "#     (주중: 최댓값→둘째, 둘째→셋째)\n",
    "# -----------------------------\n",
    "train_pre = clamp_max_to_second_by_weekpart(train_pre, date_col=DATE, key_col=KEY, target_col=TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "773a2399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TrainF] (68781, 68) features: 58\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5) 학습용 피처 생성\n",
    "# -----------------------------\n",
    "df = train_pre.copy().sort_values([KEY, DATE]).reset_index(drop=True)\n",
    "df[\"month\"] = df[DATE].dt.month\n",
    "df[\"dayofweek\"] = df[DATE].dt.dayofweek\n",
    "df[\"day\"] = df[DATE].dt.day\n",
    "df[\"dayofyear\"] = df[DATE].dt.dayofyear\n",
    "df[\"is_month_end\"] = df[DATE].dt.is_month_end.astype(int)\n",
    "df[\"is_quarter_end\"] = df[DATE].dt.is_quarter_end.astype(int)\n",
    "df[\"is_weekend\"] = (df[\"dayofweek\"]>=5).astype(int)\n",
    "\n",
    "# 미래 캘린더 피처\n",
    "for h in range(1, PREDICT+1):\n",
    "\tdth = df[DATE] + pd.to_timedelta(h, unit=\"D\")\n",
    "\tdf[f\"dow_h{h}\"]        = dth.dt.dayofweek\n",
    "\tdf[f\"is_weekend_h{h}\"] = (df[f\"dow_h{h}\"]>=5).astype(int)\n",
    "\tdf[f\"is_wkhol_h{h}\"]   = dth.isin(pd.DatetimeIndex(HOL_WEEKDAY_SET)).astype(int)\n",
    "\n",
    "# 랙/롤링\n",
    "for lag in [7,14,21]:\n",
    "\tdf[f\"lag_{lag}\"] = df.groupby(KEY)[TARGET].shift(lag)\n",
    "for lag in [1,2,3,4,5,6]:\n",
    "\tdf[f\"lag_{lag}\"] = df.groupby(KEY)[TARGET].shift(lag)\n",
    "\n",
    "for wwin in [7,14]:\n",
    "\tdf[f\"rolling_mean_{wwin}\"]   = df.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(wwin).mean())\n",
    "\tdf[f\"rolling_std_{wwin}\"]    = df.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(wwin).std())\n",
    "\tdf[f\"rolling_median_{wwin}\"] = df.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(wwin).median())\n",
    "\n",
    "df[\"rolling_mean_21\"] = df.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(21).mean())\n",
    "df[\"ratio_mean7_21\"]  = df[\"rolling_mean_7\"]/df[\"rolling_mean_21\"]\n",
    "df[\"ratio_mean14_21\"] = df[\"rolling_mean_14\"]/df[\"rolling_mean_21\"]\n",
    "\n",
    "def _slope_raw(v):\n",
    "\tm = np.isfinite(v); v = v[m]; n=v.size\n",
    "\tif n<2: return np.nan\n",
    "\tx = np.arange(n, dtype=float); xm, ym = x.mean(), v.mean()\n",
    "\tdenom = ((x-xm)**2).sum()\n",
    "\tif denom==0: return 0.0\n",
    "\treturn float(((x-xm)*(v-ym)).sum()/denom)\n",
    "\n",
    "df[\"slope_7\"]  = df.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(7).apply(_slope_raw, raw=True))\n",
    "df[\"slope_14\"] = df.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(14).apply(_slope_raw, raw=True))\n",
    "\n",
    "# 장기 무판매 플래그\n",
    "def _flag_long_zero_block(g, min_days):\n",
    "\tis_zero = (g[TARGET]==0).astype(int)\n",
    "\tblock_id = (is_zero != is_zero.shift()).cumsum()\n",
    "\tblock_len = is_zero.groupby(block_id).transform(\"sum\")\n",
    "\treturn ((is_zero==1)&(block_len>=min_days)).astype(int)\n",
    "df[\"is_long_zero_block\"] = df.groupby(KEY, sort=False).apply(\n",
    "\tlambda g: _flag_long_zero_block(g, NON_SELLING_MIN_DAYS)\n",
    ").reset_index(level=0, drop=True).astype(int)\n",
    "\n",
    "# EWM\n",
    "df[\"ewm_mean_7\"] = df.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).ewm(span=7, adjust=False, min_periods=2).mean())\n",
    "\n",
    "# 요일 Fourier\n",
    "x_dow = df[\"dayofweek\"].astype(float)\n",
    "df[\"dow_sin\"] = np.sin(2*np.pi*x_dow/7.0); df[\"dow_cos\"] = np.cos(2*np.pi*x_dow/7.0)\n",
    "\n",
    "# KEY 인코딩\n",
    "cats = pd.Index(sorted(df[KEY].astype(str).unique()))\n",
    "key2id = {k:i for i,k in enumerate(cats)}\n",
    "df[\"key_encoded\"] = df[KEY].astype(str).map(key2id).astype(\"category\")\n",
    "\n",
    "# 타깃 시프팅\n",
    "for i in range(1, PREDICT+1):\n",
    "\tdf[f\"target_{i}\"] = df.groupby(KEY)[TARGET].shift(-i)\n",
    "\n",
    "df_trainF = df.dropna().reset_index(drop=True)\n",
    "\n",
    "feat_cols = [\n",
    "\t\"month\",\"dayofweek\",\"key_encoded\",\"day\",\"dayofyear\",\"is_month_end\",\"is_quarter_end\",\"is_weekend\",\n",
    "\t\"rolling_mean_7\",\"rolling_std_7\",\"rolling_median_7\",\n",
    "\t\"rolling_mean_14\",\"rolling_std_14\",\"rolling_median_14\",\n",
    "\t\"rolling_mean_21\",\"ratio_mean7_21\",\"ratio_mean14_21\",\n",
    "\t\"slope_7\",\"slope_14\",\"ewm_mean_7\",\"dow_sin\",\"dow_cos\",\"is_long_zero_block\",\"wx_tmax\",\"wx_tavg\",\"hw_forest\",\"hw_chae\",\"hw_mono\",\n",
    "] + [c for c in df.columns if re.match(r\"^lag_\\d+$\", c)] + [c for c in df.columns if re.match(r\"^(dow_h\\d|is_weekend_h\\d|is_wkhol_h\\d)$\", c)]\n",
    "\n",
    "# float32 다운캐스팅(카테고리 제외)\n",
    "df_trainF = downcast_float32(df_trainF, exclude_cols=CATEGORICAL_COLS + [DATE, KEY])\n",
    "\n",
    "print(\"[TrainF]\", df_trainF.shape, \"features:\", len(feat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0470a355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] num_threads is set=12, n_jobs=-1 will be ignored. Current value: num_threads=12\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[fit] done. p-list: [1.1, 1.2, 1.3, 1.4]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6) 모델 학습 (p-앙상블)\n",
    "# -----------------------------\n",
    "def fit_multiout_with_p(X, y, p, seed=SEED_BASE, n_estim=N_ESTIMATORS_FULL):\n",
    "\tbase = lgb.LGBMRegressor(\n",
    "\t\tn_estimators=n_estim, learning_rate=0.04, num_leaves=63,\n",
    "\t\tfeature_fraction=0.8, bagging_fraction=0.8, bagging_freq=1,\n",
    "\t\tlambda_l1=0.1, lambda_l2=0.1, random_state=seed,\n",
    "\t\tobjective=\"tweedie\", metric=\"mae\", tweedie_variance_power=float(p),\n",
    "\t\tnum_threads=NUM_THREADS, verbose=-1,\n",
    "\t\t**LGB_DEVICE_KW\n",
    "\t)\n",
    "\tm = MultiOutputRegressor(base, n_jobs=MOR_N_JOBS)\n",
    "\tX_ = X.copy()\n",
    "\tfor c in (\"key_encoded\",\"month\",\"dayofweek\"):\n",
    "\t\tif c in X_.columns: X_[c] = X_[c].astype(\"category\")\n",
    "\tX_ = downcast_float32(X_, exclude_cols=CATEGORICAL_COLS)\n",
    "\ty_ = y.astype(np.float32)\n",
    "\tm.fit(X_, y_, categorical_feature=[c for c in (\"key_encoded\",\"month\",\"dayofweek\") if c in X_.columns])\n",
    "\treturn m\n",
    "\n",
    "models_full = {}\n",
    "X_full = df_trainF[feat_cols].copy()\n",
    "for c in (\"key_encoded\",\"month\",\"dayofweek\"):\n",
    "\tif c in X_full.columns: X_full[c] = X_full[c].astype(\"category\")\n",
    "X_full = downcast_float32(X_full, exclude_cols=CATEGORICAL_COLS)\n",
    "y_full = df_trainF[[f\"target_{i}\" for i in range(1, PREDICT+1)]].astype(np.float32).copy()\n",
    "\n",
    "for p in P_LIST:\n",
    "\tmodels_full[p] = fit_multiout_with_p(X_full, y_full, p=float(p), seed=SEED_BASE, n_estim=N_ESTIMATORS_FULL)\n",
    "\n",
    "print(\"[fit] done. p-list:\", P_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7153656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 7) 테스트 날씨/ROOM/Hwadam 준비\n",
    "# -----------------------------\n",
    "test_wday = {}\n",
    "for wp in sorted([p for p in glob.glob(\"test/meta/TEST_weather_*.csv\")\n",
    "                  if re.fullmatch(r\"TEST_weather_\\d{2}\\.csv\", os.path.basename(p))]):\n",
    "    wid = os.path.splitext(os.path.basename(wp))[0].split(\"_\")[-1]\n",
    "    fid = f\"TEST_{wid}\"\n",
    "    w = _read_csv_robust(wp).rename(columns={\"일시\": DATE})\n",
    "    w[DATE] = to_datetime_norm(w[DATE])\n",
    "    col_tmax = next(c for c in w.columns if (\"최고\" in c and \"기온\" in c))\n",
    "    col_tavg = next(c for c in w.columns if (\"평균\" in c and \"기온\" in c))\n",
    "    w_day_test = (w[[DATE, col_tmax, col_tavg]]\n",
    "                  .groupby(DATE, as_index=False).mean(numeric_only=True)\n",
    "                  .rename(columns={col_tmax:\"wx_tmax\", col_tavg:\"wx_tavg\"}))\n",
    "    test_wday[fid] = w_day_test\n",
    "\n",
    "# ROOM flags (TEST)\n",
    "room_flags_by_fid = {}\n",
    "# 교정\n",
    "for rp in sorted([p for p in glob.glob(\"test/meta/TEST_room_*.csv\")\n",
    "                  if re.fullmatch(r\"TEST_room_\\d{2}\\.csv\", os.path.basename(p))]):\n",
    "    wid = os.path.splitext(os.path.basename(rp))[0].split(\"_\")[-1]\n",
    "    fid = f\"TEST_{wid}\"\n",
    "    room_flags_by_fid[fid] = load_room_flags(rp)\n",
    "\n",
    "_w_fallback = pd.DataFrame({DATE: pd.to_datetime([]), \"wx_tmax\": [], \"wx_tavg\": []})\n",
    "\n",
    "def add_weather_feats(df_in, wday):\n",
    "    return df_in.merge(wday, on=DATE, how=\"left\")\n",
    "\n",
    "# --- hwadam 공통 merge ---\n",
    "hwadam = _read_csv_robust(\"TRAIN_hwadam.csv\").rename(columns={\"영업일자\": DATE})\n",
    "hwadam[DATE] = to_datetime_norm(hwadam[DATE])\n",
    "for c in [\"화담숲\",\"화담채\",\"모노레일\"]:\n",
    "    if c in hwadam.columns:\n",
    "        hwadam[c] = pd.to_numeric(hwadam[c], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "TARGET_STORES = {\"화담숲주막\",\"화담숲카페\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6376da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 8) 안전 전처리 함수(테스트에도 동일 적용)\n",
    "# -----------------------------\n",
    "def weekday_holiday_impute(df_in, hol_set):\n",
    "\txx = df_in.copy()\n",
    "\txx[\"dow\"] = xx[DATE].dt.dayofweek\n",
    "\txx[\"is_weekday\"] = (xx[\"dow\"] < 5).astype(int)\n",
    "\txx[\"is_weekday_hol\"] = xx[DATE].isin(hol_set).astype(int)\n",
    "\n",
    "\touts = []\n",
    "\tfor k, g in xx.groupby(KEY, sort=False):\n",
    "\t\tg = g.sort_values(DATE).copy()\n",
    "\t\tend_date = g[DATE].max()\n",
    "\t\tcand = g[(g[\"is_weekday\"]==1) & (g[\"is_weekday_hol\"]==0)].copy()\n",
    "\t\tall_weekday_zero = (cand[TARGET].sum()==0)\n",
    "\n",
    "\t\tdef _wmean(vals, dates, end_date, decay=0.90, lastweek_window=7, boost=0.50):\n",
    "\t\t\tif len(vals)==0: return np.nan\n",
    "\t\t\tvals = np.asarray(vals,float); dates = pd.to_datetime(dates)\n",
    "\t\t\tdelta = (end_date - dates).days.astype(float)\n",
    "\t\t\tw = decay ** delta\n",
    "\t\t\tw = np.where(dates >= end_date - pd.Timedelta(days=lastweek_window-1), w*(1+boost), w)\n",
    "\t\t\tw = np.clip(w, 1e-6, None)\n",
    "\t\t\treturn float(np.sum(w*vals)/np.sum(w))\n",
    "\n",
    "\t\tfor idx, row in g.loc[(g[\"is_weekday\"]==1) & (g[\"is_weekday_hol\"]==1)].iterrows():\n",
    "\t\t\tif all_weekday_zero:\n",
    "\t\t\t\tg.at[idx, TARGET] = 0; continue\n",
    "\t\t\tpool = cand[cand[\"dow\"]==int(row[\"dow\"])]\n",
    "\t\t\tbase = _wmean(pool[TARGET].values, pool[DATE].values, end_date) if len(pool)>0 else \\\n",
    "\t\t\t\t   _wmean(cand[TARGET].values, cand[DATE].values, end_date)   # (오타 fix)\n",
    "\t\t\tt7 = row[DATE] - pd.Timedelta(days=7)\n",
    "\t\t\tprev = g[(g[DATE]==t7) & (g[\"is_weekday\"]==1) & (g[\"is_weekday_hol\"]==0)]\n",
    "\t\t\tval_t7 = float(prev[TARGET].iloc[0]) if len(prev)==1 else np.nan\n",
    "\t\t\tif np.isfinite(base):\n",
    "\t\t\t\ty_hat = base if not np.isfinite(val_t7) else 0.65*base + 0.35*val_t7\n",
    "\t\t\t\tg.at[idx, TARGET] = int(max(0, round(y_hat)))\n",
    "\t\t\telse:\n",
    "\t\t\t\tg.at[idx, TARGET] = 0\n",
    "\t\touts.append(g)\n",
    "\treturn pd.concat(outs, axis=0).drop(columns=[\"dow\",\"is_weekday\",\"is_weekday_hol\"])\n",
    "\n",
    "\n",
    "\n",
    "def spike_clamp(df_in, hol_set):\n",
    "\tx2 = df_in.copy()\n",
    "\tx2[\"dow\"] = x2[DATE].dt.dayofweek\n",
    "\tx2[\"is_nonhol_weekday\"] = ((x2[\"dow\"]<5) & (~x2[DATE].isin(hol_set))).astype(int)\n",
    "\tx2[\"is_hol_wk\"] = x2[DATE].isin(hol_set).astype(int)\n",
    "\n",
    "\touts = []\n",
    "\tfor k, g in x2.groupby(KEY, sort=False):\n",
    "\t\tg = g.copy()\n",
    "\t\tg[\"med_wd_dow\"] = np.nan\n",
    "\t\tfor d in range(5):\n",
    "\t\t\tidx = (g[\"dow\"]==d) & (g[\"is_nonhol_weekday\"]==1)\n",
    "\t\t\ts = g.loc[idx, TARGET].astype(float)\n",
    "\t\t\tmed = s.shift(1).rolling(window=4, min_periods=2).median()\n",
    "\t\t\tg.loc[idx, \"med_wd_dow\"] = med.values\n",
    "\t\tthr_up = 1.25 * g[\"med_wd_dow\"]\n",
    "\t\tadj = (g[\"is_hol_wk\"]==1) & np.isfinite(g[\"med_wd_dow\"]) & (g[TARGET] > thr_up)\n",
    "\t\tg.loc[adj, TARGET] = np.maximum(0.0, np.round(1.10 * g.loc[adj, \"med_wd_dow\"]))\n",
    "\t\touts.append(g.drop(columns=[\"med_wd_dow\"]))\n",
    "\treturn pd.concat(outs, axis=0).drop(columns=[\"dow\",\"is_nonhol_weekday\",\"is_hol_wk\"])\n",
    "\n",
    "# -----------------------------\n",
    "# 9) 예측 (앵커 앙상블 + p 앙상블)\n",
    "# -----------------------------\n",
    "all_preds = []\n",
    "\n",
    "def build_feats(df_in):\n",
    "\tf = df_in.copy().sort_values([KEY, DATE])\n",
    "\tf[\"month\"] = f[DATE].dt.month\n",
    "\tf[\"dayofweek\"] = f[DATE].dt.dayofweek\n",
    "\tf[\"day\"] = f[DATE].dt.day\n",
    "\tf[\"dayofyear\"] = f[DATE].dt.dayofyear\n",
    "\tf[\"is_month_end\"]   = f[DATE].dt.is_month_end.astype(int)\n",
    "\tf[\"is_quarter_end\"] = f[DATE].dt.is_quarter_end.astype(int)\n",
    "\tf[\"is_weekend\"]     = (f[\"dayofweek\"]>=5).astype(int)\n",
    "\n",
    "\tfor h in range(1, PREDICT+1):\n",
    "\t\tdth = f[DATE] + pd.to_timedelta(h, unit=\"D\")\n",
    "\t\tf[f\"dow_h{h}\"]        = dth.dt.dayofweek\n",
    "\t\tf[f\"is_weekend_h{h}\"] = (f[f\"dow_h{h}\"]>=5).astype(int)\n",
    "\t\tf[f\"is_wkhol_h{h}\"]   = dth.isin(pd.DatetimeIndex(HOL_WEEKDAY_SET)).astype(int)\n",
    "\n",
    "\tfor lag in [7,14,21]: f[f\"lag_{lag}\"] = f.groupby(KEY)[TARGET].shift(lag)\n",
    "\tfor lag in [1,2,3,4,5,6]: f[f\"lag_{lag}\"] = f.groupby(KEY)[TARGET].shift(lag)\n",
    "\n",
    "\tfor wwin in [7,14]:\n",
    "\t\tf[f\"rolling_mean_{wwin}\"]   = f.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(wwin).mean())\n",
    "\t\tf[f\"rolling_std_{wwin}\"]    = f.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(wwin).std())\n",
    "\t\tf[f\"rolling_median_{wwin}\"] = f.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(wwin).median())\n",
    "\n",
    "\tf[\"rolling_mean_21\"] = f.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(21).mean())\n",
    "\tf[\"ratio_mean7_21\"]  = f[\"rolling_mean_7\"]/f[\"rolling_mean_21\"]\n",
    "\tf[\"ratio_mean14_21\"] = f[\"rolling_mean_14\"]/f[\"rolling_mean_21\"]\n",
    "\n",
    "\tdef _slope(v):\n",
    "\t\tv = v[np.isfinite(v)]\n",
    "\t\tif v.size < 2: return np.nan\n",
    "\t\tx = np.arange(v.size, dtype=float)\n",
    "\t\txm, ym = x.mean(), v.mean()\n",
    "\t\tdenom = ((x-xm)**2).sum()\n",
    "\t\treturn 0.0 if denom==0 else float(((x-xm)*(v-ym)).sum()/denom)\n",
    "\n",
    "\tf[\"slope_7\"]  = f.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(7).apply(_slope, raw=True))\n",
    "\tf[\"slope_14\"] = f.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(14).apply(_slope, raw=True))\n",
    "\tf[\"ewm_mean_7\"] = f.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).ewm(span=7, adjust=False, min_periods=2).mean())\n",
    "\n",
    "\tx_dow = f[\"dayofweek\"].astype(float)\n",
    "\tf[\"dow_sin\"] = np.sin(2*np.pi*x_dow/7.0); f[\"dow_cos\"] = np.cos(2*np.pi*x_dow/7.0)\n",
    "\n",
    "\tf[\"key_encoded\"] = f[KEY].astype(str).map(key2id).astype(\"category\")\n",
    "\n",
    "\tdef _flag_lzb_local(g):\n",
    "\t\tiz = (g[TARGET]==0).astype(int)\n",
    "\t\tbid = (iz != iz.shift()).cumsum()\n",
    "\t\tblen = iz.groupby(bid).transform(\"sum\")\n",
    "\t\treturn ((iz==1) & (blen >= NON_SELLING_MIN_DAYS)).astype(int)\n",
    "\tf[\"is_long_zero_block\"] = f.groupby(KEY, sort=False).apply(_flag_lzb_local).reset_index(level=0, drop=True).astype(int)\n",
    "\n",
    "\tf = downcast_float32(f, exclude_cols=CATEGORICAL_COLS + [DATE, KEY])\n",
    "\treturn f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b00a2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for path in test_files:\n",
    "\tfid = os.path.splitext(os.path.basename(path))[0]  # TEST_xx\n",
    "\ttdf = _read_csv_robust(path)\n",
    "\ttdf[DATE] = to_datetime_norm(tdf[DATE])\n",
    "\ttdf = tdf.sort_values([KEY, DATE]).reset_index(drop=True)\n",
    "\n",
    "\t# (A) 평일 공휴일 imputing → (B) 급등 클램프 → (C) ROOM 보정 → (D) 날씨 결합\n",
    "\ttdf_imp  = weekday_holiday_impute(tdf, HOL_WEEKDAY_SET)\n",
    "\ttdf_safe = spike_clamp(tdf_imp, HOL_WEEKDAY_SET)\n",
    "\ttdf_room = apply_room_zero_fix(tdf_safe, room_flags_by_fid.get(fid, pd.DataFrame()), window=28, min_obs=2)\n",
    "\ttdf_room = add_weather_feats(tdf_room, test_wday.get(fid, _w_fallback))\n",
    "\ttdf_room = add_hwadam_feats(tdf_room, hwadam)   # 날짜가 없으면 0으로 남음\n",
    "\n",
    "\n",
    "\t# (E) [마지막 전처리] 주중: 최댓값→둘째, 둘째→셋째 / 주말: 최댓값→둘째\n",
    "\ttdf_room = clamp_max_to_second_by_weekpart(tdf_room, date_col=DATE, key_col=KEY, target_col=TARGET)\n",
    "\n",
    "\this = tdf_room.sort_values([KEY, DATE])\n",
    "\tlast_date = his[DATE].max()\n",
    "\tdate_set = set(his[DATE])\n",
    "\tanchors = sorted(d for d in (last_date - pd.to_timedelta(np.arange(ANCHOR_K_FULL), \"D\")) if d in date_set)\n",
    "\n",
    "\tbucket = {}\n",
    "\tfor ad in anchors:\n",
    "\t\tsub = his[his[DATE] <= ad].copy()\n",
    "\t\tFeat = build_feats(sub)\n",
    "\t\trowA = Feat[Feat[DATE]==ad].copy()\n",
    "\t\tif rowA.empty:\n",
    "\t\t\tcontinue\n",
    "\t\tXrow = rowA[feat_cols].copy()\n",
    "\t\tfor c in (\"key_encoded\",\"month\",\"dayofweek\"):\n",
    "\t\t\tif c in Xrow.columns: Xrow[c] = Xrow[c].astype(\"category\")\n",
    "\t\tXrow = downcast_float32(Xrow, exclude_cols=CATEGORICAL_COLS)\n",
    "\n",
    "\t\t# p-가중 앙상블\n",
    "\t\tY_mix = None\n",
    "\t\tfor p, mdl in models_full.items():\n",
    "\t\t\tYp = mdl.predict(Xrow)  # (n_keys, 7)\n",
    "\t\t\tw  = P_WEIGHTS.get(p, 0.0)\n",
    "\t\t\tY_mix = (w*Yp) if Y_mix is None else (Y_mix + w*Yp)\n",
    "\n",
    "\t\tmeta = rowA[[KEY,DATE]].reset_index(drop=True)\n",
    "\t\tfor i in range(len(meta)):\n",
    "\t\t\tkeyi = meta.at[i, KEY]\n",
    "\t\t\tfor h in range(PREDICT):\n",
    "\t\t\t\tdtp = (ad + pd.Timedelta(days=h+1)).normalize()\n",
    "\t\t\t\tbucket.setdefault((dtp, keyi), []).append(float(Y_mix[i, h]))\n",
    "\n",
    "\tfor (dtp, keyi), vals in bucket.items():\n",
    "\t\tall_preds.append({DATE: dtp, KEY: keyi, TARGET: float(np.mean(vals))})\n",
    "\n",
    "sub_long = pd.DataFrame(all_preds).copy()\n",
    "sub_long[DATE] = to_datetime_norm(sub_long[DATE])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b0aa83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 10) 블록 통계(후처리용) — 예측과 동일 기준(ROOM 포함)\n",
    "# -----------------------------\n",
    "date_to_file, block_pos_values, block_lengths, weekend_means = {}, {}, {}, {}\n",
    "\n",
    "for p in test_files:\n",
    "\tfid = os.path.basename(p).split(\".\")[0]\n",
    "\tdfb = _read_csv_robust(p)\n",
    "\tdfb[DATE] = to_datetime_norm(dfb[DATE])\n",
    "\tdfb = dfb.sort_values([KEY, DATE]).reset_index(drop=True)\n",
    "\n",
    "\t# (A) 평일 공휴일 imputing → (B) 급등 클램프 → (C) ROOM 보정\n",
    "\ttdf_imp_stat  = weekday_holiday_impute(dfb, HOL_WEEKDAY_SET)\n",
    "\ttdf_safe_stat = spike_clamp(tdf_imp_stat, HOL_WEEKDAY_SET)\n",
    "\ttdf_safe_stat = apply_room_zero_fix(tdf_safe_stat, room_flags_by_fid.get(fid, pd.DataFrame()), window=28, min_obs=2)\n",
    "\n",
    "\t# (D) [마지막 전처리] 주중: 최댓값→둘째, 둘째→셋째 / 주말: 최댓값→둘째\n",
    "\ttdf_safe_stat = clamp_max_to_second_by_weekpart(tdf_safe_stat, date_col=DATE, key_col=KEY, target_col=TARGET)\n",
    "\n",
    "\ttdf_safe_stat = tdf_safe_stat.sort_values([KEY, DATE])\n",
    "\n",
    "\tlast = tdf_safe_stat[DATE].max()\n",
    "\tfor h in range(1, PREDICT+1):\n",
    "\t\tdate_to_file[(last + pd.Timedelta(days=h)).strftime(\"%Y-%m-%d\")] = fid\n",
    "\tfor k_i, g in tdf_safe_stat.groupby(KEY):\n",
    "\t\tg = g.sort_values(DATE)\n",
    "\t\tpos = g.loc[g[TARGET] > 0, TARGET].astype(float).values\n",
    "\t\tblock_pos_values[(fid, k_i)] = pos\n",
    "\t\tblock_lengths[(fid, k_i)] = int(g.shape[0])\n",
    "\t\twknd = g[g[DATE].dt.dayofweek >= 5][TARGET].astype(float)\n",
    "\t\tweekend_means[(fid, k_i)] = float(wknd.mean()) if wknd.size > 0 else np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "811238de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[postprocess] rows: 21710\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 11) 후처리\n",
    "# -----------------------------\n",
    "def is_metric_target_post(k):\n",
    "\ts = str(k)\n",
    "\tif \"공깃밥\" in s: return False\n",
    "\tif \"단체\" in s: return True\n",
    "\treturn False\n",
    "\n",
    "# (A) 평일 공휴일이면 주말 평균으로 대체\n",
    "if APPLY_METRIC_AWARE_WK_HOLOV:\n",
    "\trows = []\n",
    "\tfor _, r in sub_long.iterrows():\n",
    "\t\tdt = r[DATE]\n",
    "\t\tif (dt.weekday() < 5) and (dt in HOL_WEEKDAY_SET):\n",
    "\t\t\tfid = date_to_file.get(dt.strftime(\"%Y-%m-%d\"))\n",
    "\t\t\twk = weekend_means.get((fid, r[KEY])) if fid is not None else np.nan\n",
    "\t\t\tval = float(wk) if np.isfinite(wk) else float(r[TARGET])\n",
    "\t\telse:\n",
    "\t\t\tval = float(r[TARGET])\n",
    "\t\trows.append(val)\n",
    "\tsub_long[TARGET] = np.array(rows, dtype=float)\n",
    "\n",
    "# (B) weighted-SMAPE 기반 블렌딩\n",
    "def _weighted_smape_constant(pos_vals, n_days, decay=0.92, clamp_k=0.50, beta_soft=0.50):\n",
    "\tpos = np.asarray(pos_vals, float)\n",
    "\tif pos.size == 0: return 1, 0.0\n",
    "\tpos = np.sort(pos); q1,q2,q3 = np.percentile(pos,[25,50,75]); iqr = q3-q1; p95 = np.percentile(pos,95)\n",
    "\tw = np.array([decay**(pos.size-1-i) for i in range(pos.size)], float); w /= w.sum()\n",
    "\tbase_cands = np.unique(np.round(np.r_[pos,q1,q2,q3,(q1+q3)/2,p95]).astype(int))\n",
    "\tlo = max(1, int(np.floor(max(1, q1 - clamp_k*iqr)))); hi = int(np.ceil(min(max(base_cands.max(),2), p95*1.10)))\n",
    "\tcands = np.unique(np.r_[base_cands, np.arange(lo, max(lo+1, hi+1))])\n",
    "\tdef _wsmape(c): c=float(c); return np.sum(w*(2.0*np.abs(c-pos)/(np.abs(c)+pos)))\n",
    "\tscores = np.array([_wsmape(c) for c in cands]); c_star = int(cands[np.argmin(scores)])\n",
    "\tclamp_lo = max(1, int(np.floor(q1 - clamp_k*iqr))); clamp_hi = int(np.ceil(q3 + clamp_k*iqr))\n",
    "\tc_clip = int(np.clip(c_star, clamp_lo, clamp_hi))\n",
    "\tc_final = int(np.round((1 - beta_soft)*c_star + beta_soft*c_clip)); c_final = max(1, c_final)\n",
    "\tzero_rate = 1.0 - (pos.size / max(1, n_days))\n",
    "\tiqr_ratio = (iqr / (q2 + 1e-9)) if q2 > 0 else 0.0; iqr_ratio = float(np.clip(iqr_ratio, 0.0, 2.0))\n",
    "\talpha_raw = 0.6*zero_rate + 0.4*(iqr_ratio / (1.0 + iqr_ratio))\n",
    "\talpha = float(np.clip(alpha_raw, 0.0, 0.5))\n",
    "\treturn c_final, alpha\n",
    "\n",
    "if APPLY_METRIC_AWARE_WSMAPE:\n",
    "\tnew_vals = []\n",
    "\tfor _, r in sub_long.iterrows():\n",
    "\t\tk = r[KEY]\n",
    "\t\tif not is_metric_target_post(k):\n",
    "\t\t\tnew_vals.append(float(r[TARGET])); continue\n",
    "\t\tfid = date_to_file.get(r[DATE].strftime(\"%Y-%m-%d\"))\n",
    "\t\tif fid is None:\n",
    "\t\t\tnew_vals.append(float(r[TARGET])); continue\n",
    "\t\tpos = block_pos_values.get((fid, k), np.array([]))\n",
    "\t\tnd  = block_lengths.get((fid, k), INPUT_WINDOW_DAYS)\n",
    "\t\tc, a = _weighted_smape_constant(pos, nd)\n",
    "\t\ty = float(r[TARGET]); y_new = (1.0 - a)*y + a*float(c)\n",
    "\t\tnew_vals.append(y_new)\n",
    "\tsub_long[TARGET] = np.array(new_vals, dtype=float)\n",
    "\n",
    "# 라운딩 & 최소치 보정\n",
    "sub_long[TARGET] = round_nonneg(sub_long[TARGET].values, BEST_THR).astype(int)\n",
    "\n",
    "if FORCE_ACTIVE_MIN1 or FORCE_GLOBAL_MIN1:\n",
    "\tif FORCE_ACTIVE_MIN1:\n",
    "\t\tupd = []\n",
    "\t\tfor _, r in sub_long.iterrows():\n",
    "\t\t\ty = int(r[TARGET])\n",
    "\t\t\tfid = date_to_file.get(r[DATE].strftime(\"%Y-%m-%d\"))\n",
    "\t\t\tif (y == 0) and (fid is not None) and is_metric_target_post(r[KEY]):\n",
    "\t\t\t\tpos = block_pos_values.get((fid, r[KEY]), np.array([]))\n",
    "\t\t\t\tif pos.size > 0: y = 1\n",
    "\t\t\tupd.append(y)\n",
    "\t\tsub_long[TARGET] = np.array(upd, dtype=int)\n",
    "\tif FORCE_GLOBAL_MIN1:\n",
    "\t\tsub_long.loc[sub_long[TARGET] == 0, TARGET] = 1\n",
    "\n",
    "print(\"[postprocess] rows:\", len(sub_long))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ed07745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVE] -> submission_roomroom_hwadam추가.csv\n",
      "         영업일자  느티나무 셀프BBQ_1인 수저세트  느티나무 셀프BBQ_BBQ55(단체)  \\\n",
      "0  TEST_00+1일                   7                    56   \n",
      "1  TEST_00+2일                   2                    59   \n",
      "\n",
      "   느티나무 셀프BBQ_대여료 30,000원  느티나무 셀프BBQ_대여료 60,000원  느티나무 셀프BBQ_대여료 90,000원  \\\n",
      "0                       6                       3                       1   \n",
      "1                       1                       1                       1   \n",
      "\n",
      "   느티나무 셀프BBQ_스프라이트 (단체)  느티나무 셀프BBQ_신라면  느티나무 셀프BBQ_쌈장  느티나무 셀프BBQ_육개장 사발면  \\\n",
      "0                     17               2              1                   1   \n",
      "1                     19               1              1                   1   \n",
      "\n",
      "   ...  화담숲주막_스프라이트  화담숲주막_참살이 막걸리  화담숲주막_찹쌀식혜  화담숲주막_콜라  화담숲주막_해물파전  \\\n",
      "0  ...            4             12          12         4          43   \n",
      "1  ...            1              1           1         1           2   \n",
      "\n",
      "   화담숲카페_메밀미숫가루  화담숲카페_아메리카노 HOT  화담숲카페_아메리카노 ICE  화담숲카페_카페라떼 ICE  \\\n",
      "0            19                5               19               6   \n",
      "1             1                1                2               1   \n",
      "\n",
      "   화담숲카페_현미뻥스크림  \n",
      "0            10  \n",
      "1             1  \n",
      "\n",
      "[2 rows x 168 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# 12) sample 형식으로 pivot → 저장\n",
    "# -----------------------------\n",
    "OUT_PATH = \"submission_roomroom_hwadam추가.csv\"\n",
    "\n",
    "sample = _read_csv_robust(\"sample_submission.csv\")\n",
    "label_col = sample.columns[0]\n",
    "\n",
    "# date_label 매핑: \"TEST_xx+N일\"\n",
    "date_label = {}\n",
    "for fp in test_files:\n",
    "\ttdf = _read_csv_robust(fp)\n",
    "\ttdf[DATE] = to_datetime_norm(tdf[DATE])\n",
    "\tfid = os.path.basename(fp).split(\".\")[0]  # TEST_xx\n",
    "\tlast = tdf[DATE].max()\n",
    "\tfor i in range(PREDICT):\n",
    "\t\tdate_label[(last + pd.Timedelta(days=i+1)).strftime(\"%Y-%m-%d\")] = f\"{fid}+{i+1}일\"\n",
    "\n",
    "sub_long = sub_long.copy()\n",
    "sub_long[\"date_label\"] = sub_long[DATE].dt.strftime(\"%Y-%m-%d\").map(date_label)\n",
    "\n",
    "pivot = sub_long.pivot_table(index=\"date_label\", columns=KEY, values=TARGET, aggfunc=\"first\")\n",
    "final = sample.set_index(label_col)\n",
    "common = [c for c in final.columns if c in pivot.columns]\n",
    "if len(common)>0:\n",
    "\tfinal[common] = final[common].combine_first(pivot[common])\n",
    "\tfinal.update(pivot[common])\n",
    "\n",
    "final = final.fillna(1).astype(np.int64).reset_index()\n",
    "final.columns = sample.columns\n",
    "\n",
    "final.to_csv(OUT_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"[SAVE] ->\", OUT_PATH)\n",
    "print(final.head(2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
