{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "WTfDtsqxHtKK",
   "metadata": {
    "id": "WTfDtsqxHtKK"
   },
   "source": [
    "# LG Aimers 35→7 Tweedie(LightGBM) — 함수 최소화 디버깅 노트북\n",
    "단계별로 편집·재실행 가능. 핵심 로직 동일.\n",
    "날씨 평균기온, 최고기온 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cA0vvCGGPHd4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cA0vvCGGPHd4",
    "outputId": "9869db61-3243-4178-f33e-6b7b26d0a2f5"
   },
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZRljsvHAHtKP",
   "metadata": {
    "id": "ZRljsvHAHtKP"
   },
   "source": [
    "## 0. 공통 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vRItH79jHtKR",
   "metadata": {
    "id": "vRItH79jHtKR"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os, re, glob, unicodedata, warnings\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 고정 설정\n",
    "SEED_BASE = 42\n",
    "np.random.seed(SEED_BASE)\n",
    "PREDICT, INPUT_WINDOW_DAYS = 7, 35\n",
    "DATE, KEY, TARGET = \"영업일자\",\"영업장명_메뉴명\",\"매출수량\"\n",
    "\n",
    "SEEDS_FULL, N_ESTIMATORS_FULL, ANCHOR_K_FULL = 1, 1200, 7\n",
    "SEEDS_SEARCH, N_ESTIMATORS_SEARCH, ANCHOR_K_SEARCH = 1, 400, 3\n",
    "\n",
    "NON_SELLING_MIN_DAYS = 14\n",
    "APPLY_METRIC_AWARE_WSMAPE   = True\n",
    "APPLY_METRIC_AWARE_WK_HOLOV = True\n",
    "FORCE_ACTIVE_MIN1 = True\n",
    "FORCE_GLOBAL_MIN1 = True\n",
    "\n",
    "CATEGORICAL_COLS = [\"key_encoded\",\"month\",\"dayofweek\"]\n",
    "EXTRA_GROUP_KEYS = {\"연회장_Cass Beer\", \"연회장_Regular Coffee\"}\n",
    "BRUNCH_WD = \"미라시아_브런치(대인) 주중\"\n",
    "BRUNCH_WE = \"미라시아_브런치(대인) 주말\"\n",
    "\n",
    "# 작은 헬퍼(불가피)\n",
    "to_datetime_norm = lambda s: pd.to_datetime(s, errors=\"coerce\").dt.normalize()\n",
    "\n",
    "def smape_comp(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, float); y_pred = np.asarray(y_pred, float)\n",
    "    m = (y_true != 0)\n",
    "    if not np.any(m): return np.nan\n",
    "    yt, yp = y_true[m], y_pred[m]\n",
    "    return np.mean(2*np.abs(yp-yt)/(np.abs(yt)+np.abs(yp))) * 100\n",
    "\n",
    "def round_nonneg(pred, thr):\n",
    "    pred = np.maximum(pred, 0.0)\n",
    "    frac = pred - np.floor(pred)\n",
    "    out  = np.where(frac >= thr, np.floor(pred)+1, np.floor(pred))\n",
    "    return np.maximum(out, 0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t3tNKljjHtKW",
   "metadata": {
    "id": "t3tNKljjHtKW"
   },
   "source": [
    "## 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "YsHJzeo8OnoV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "YsHJzeo8OnoV",
    "outputId": "6c188e17-d9e2-49fc-da4b-3ed15a03a572"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영업일자</th>\n",
       "      <th>느티나무 셀프BBQ</th>\n",
       "      <th>담하</th>\n",
       "      <th>라그로타</th>\n",
       "      <th>미라시아</th>\n",
       "      <th>카페테리아</th>\n",
       "      <th>포레스트릿</th>\n",
       "      <th>화담숲주막</th>\n",
       "      <th>화담숲카페</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>2024-06-11</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>2024-06-12</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>2024-06-13</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>2024-06-14</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>2024-06-15</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           영업일자  느티나무 셀프BBQ  담하  라그로타  미라시아  카페테리아  포레스트릿  화담숲주막  화담숲카페\n",
       "0    2023-01-01           0   0     0     2      0      0      0      0\n",
       "1    2023-01-02           0   6     0     2      0      0      0      0\n",
       "2    2023-01-03           4   4     0     1      2      0      0      0\n",
       "3    2023-01-04           0   2     0     3      1      0      0      0\n",
       "4    2023-01-05           4   2     0     0      1      0      0      0\n",
       "..          ...         ...  ..   ...   ...    ...    ...    ...    ...\n",
       "527  2024-06-11          19   6     0     3      4      0      0      0\n",
       "528  2024-06-12          10  13    10     1      1      0      0      0\n",
       "529  2024-06-13          15   4     0     4     12      0      0      0\n",
       "530  2024-06-14          21   8     0     5      6      0      0      0\n",
       "531  2024-06-15           8   6     0     0      4      0      0      0\n",
       "\n",
       "[532 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_m =  pd.read_csv('TRAIN_group.csv')\n",
    "group_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d75525c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "d75525c8",
    "outputId": "8a1f7b4c-8ebe-4dc7-cb36-91f15cf2cf39"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일시</th>\n",
       "      <th>평균기온(℃)</th>\n",
       "      <th>최고기온(℃)</th>\n",
       "      <th>최고기온시각</th>\n",
       "      <th>최저기온(℃)</th>\n",
       "      <th>최저기온시각</th>\n",
       "      <th>일교차</th>\n",
       "      <th>강수량(mm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>13:55</td>\n",
       "      <td>-7.7</td>\n",
       "      <td>08:14</td>\n",
       "      <td>13.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>14:29</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>07:45</td>\n",
       "      <td>10.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>14:58</td>\n",
       "      <td>-14.3</td>\n",
       "      <td>08:03</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>15:34</td>\n",
       "      <td>-10.8</td>\n",
       "      <td>03:28</td>\n",
       "      <td>14.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>15:31</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>05:58</td>\n",
       "      <td>12.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>2024-06-11</td>\n",
       "      <td>25.4</td>\n",
       "      <td>31.8</td>\n",
       "      <td>14:57</td>\n",
       "      <td>20.1</td>\n",
       "      <td>01:51</td>\n",
       "      <td>11.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>2024-06-12</td>\n",
       "      <td>24.9</td>\n",
       "      <td>33.3</td>\n",
       "      <td>15:36</td>\n",
       "      <td>16.4</td>\n",
       "      <td>05:16</td>\n",
       "      <td>16.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>2024-06-13</td>\n",
       "      <td>25.5</td>\n",
       "      <td>34.3</td>\n",
       "      <td>15:08</td>\n",
       "      <td>16.9</td>\n",
       "      <td>05:42</td>\n",
       "      <td>17.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>2024-06-14</td>\n",
       "      <td>25.8</td>\n",
       "      <td>33.8</td>\n",
       "      <td>14:25</td>\n",
       "      <td>17.7</td>\n",
       "      <td>05:18</td>\n",
       "      <td>16.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>2024-06-15</td>\n",
       "      <td>24.0</td>\n",
       "      <td>27.7</td>\n",
       "      <td>11:30</td>\n",
       "      <td>21.0</td>\n",
       "      <td>05:52</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             일시  평균기온(℃)  최고기온(℃) 최고기온시각  최저기온(℃) 최저기온시각   일교차  강수량(mm)\n",
       "0    2023-01-01     -1.7      5.5  13:55     -7.7  08:14  13.2      NaN\n",
       "1    2023-01-02     -4.1      1.3  14:29     -9.0  07:45  10.3      NaN\n",
       "2    2023-01-03     -6.2      1.7  14:58    -14.3  08:03  16.0      NaN\n",
       "3    2023-01-04     -3.8      3.9  15:34    -10.8  03:28  14.7      NaN\n",
       "4    2023-01-05     -5.3      2.3  15:31    -10.6  05:58  12.9      NaN\n",
       "..          ...      ...      ...    ...      ...    ...   ...      ...\n",
       "527  2024-06-11     25.4     31.8  14:57     20.1  01:51  11.7      NaN\n",
       "528  2024-06-12     24.9     33.3  15:36     16.4  05:16  16.9      NaN\n",
       "529  2024-06-13     25.5     34.3  15:08     16.9  05:42  17.4      NaN\n",
       "530  2024-06-14     25.8     33.8  14:25     17.7  05:18  16.1      NaN\n",
       "531  2024-06-15     24.0     27.7  11:30     21.0  05:52   6.7      3.7\n",
       "\n",
       "[532 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_m  = pd.read_csv('TRAIN_weather.csv')\n",
    "weather_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wdW6OvjnM4qU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "wdW6OvjnM4qU",
    "outputId": "fca47e19-0a53-426c-c059-802cdb619779"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영업일자</th>\n",
       "      <th>8시</th>\n",
       "      <th>9시</th>\n",
       "      <th>10시</th>\n",
       "      <th>11시</th>\n",
       "      <th>12시</th>\n",
       "      <th>13시</th>\n",
       "      <th>14시</th>\n",
       "      <th>15시</th>\n",
       "      <th>16시</th>\n",
       "      <th>...</th>\n",
       "      <th>23시</th>\n",
       "      <th>24시</th>\n",
       "      <th>1시</th>\n",
       "      <th>2시</th>\n",
       "      <th>3시</th>\n",
       "      <th>4시</th>\n",
       "      <th>5시</th>\n",
       "      <th>6시</th>\n",
       "      <th>7시</th>\n",
       "      <th>1일내장객</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>585.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>947.0</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>1815.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>...</td>\n",
       "      <td>813.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5759.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>387.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>793.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>1338.0</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>1716.0</td>\n",
       "      <td>1494.0</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4574.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>396.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>976.0</td>\n",
       "      <td>1253.0</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>842.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4585.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>404.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>718.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>1411.0</td>\n",
       "      <td>1558.0</td>\n",
       "      <td>1415.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1189.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4634.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>436.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1086.0</td>\n",
       "      <td>1355.0</td>\n",
       "      <td>1683.0</td>\n",
       "      <td>1849.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>916.0</td>\n",
       "      <td>443.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>2024-06-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>2024-06-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>2024-06-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>2024-06-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>2024-06-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           영업일자     8시     9시    10시     11시     12시     13시     14시     15시  \\\n",
       "0    2023-01-01  585.0  552.0  947.0  1284.0  1658.0  1815.0  1970.0  1746.0   \n",
       "1    2023-01-02  387.0  421.0  793.0  1089.0  1338.0  1598.0  1716.0  1494.0   \n",
       "2    2023-01-03  396.0  375.0  710.0   976.0  1253.0  1491.0  1580.0  1387.0   \n",
       "3    2023-01-04  404.0  392.0  718.0   983.0  1198.0  1411.0  1558.0  1415.0   \n",
       "4    2023-01-05  436.0  435.0  750.0  1086.0  1355.0  1683.0  1849.0  1658.0   \n",
       "..          ...    ...    ...    ...     ...     ...     ...     ...     ...   \n",
       "527  2024-06-11    NaN    NaN    NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "528  2024-06-12    NaN    NaN    NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "529  2024-06-13    NaN    NaN    NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "530  2024-06-14    NaN    NaN    NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "531  2024-06-15    NaN    NaN    NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "        16시  ...     23시    24시     1시     2시    3시    4시    5시   6시   7시  \\\n",
       "0    1467.0  ...   813.0  577.0  268.0   57.0  19.0   6.0   3.0  0.0  3.0   \n",
       "1    1279.0  ...  1122.0  834.0  391.0   91.0  27.0   9.0   4.0  0.0  1.0   \n",
       "2    1224.0  ...  1177.0  842.0  359.0  100.0  33.0  11.0   1.0  1.0  1.0   \n",
       "3    1203.0  ...  1189.0  886.0  373.0  107.0  34.0  13.0   5.0  1.0  0.0   \n",
       "4    1471.0  ...  1336.0  916.0  443.0  121.0  40.0  20.0  15.0  2.0  0.0   \n",
       "..      ...  ...     ...    ...    ...    ...   ...   ...   ...  ...  ...   \n",
       "527     NaN  ...     NaN    NaN    NaN    NaN   NaN   NaN   NaN  NaN  NaN   \n",
       "528     NaN  ...     NaN    NaN    NaN    NaN   NaN   NaN   NaN  NaN  NaN   \n",
       "529     NaN  ...     NaN    NaN    NaN    NaN   NaN   NaN   NaN  NaN  NaN   \n",
       "530     NaN  ...     NaN    NaN    NaN    NaN   NaN   NaN   NaN  NaN  NaN   \n",
       "531     NaN  ...     NaN    NaN    NaN    NaN   NaN   NaN   NaN  NaN  NaN   \n",
       "\n",
       "      1일내장객  \n",
       "0    5759.0  \n",
       "1    4574.0  \n",
       "2    4585.0  \n",
       "3    4634.0  \n",
       "4    5371.0  \n",
       "..      ...  \n",
       "527     NaN  \n",
       "528     NaN  \n",
       "529     NaN  \n",
       "530     NaN  \n",
       "531     NaN  \n",
       "\n",
       "[532 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ski_m = pd.read_csv('TRAIN_ski.csv')\n",
    "ski_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "K8ig97UPHtKb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "K8ig97UPHtKb",
    "outputId": "f437a727-6ec9-425b-dd07-a7a31f1afc3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88844, 3) keys: 167 기간: 2023-01-01 → 2024-06-15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영업일자</th>\n",
       "      <th>영업장명_메뉴명</th>\n",
       "      <th>매출수량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        영업일자            영업장명_메뉴명  매출수량\n",
       "0 2023-01-01  느티나무 셀프BBQ_1인 수저세트     0\n",
       "1 2023-01-02  느티나무 셀프BBQ_1인 수저세트     0\n",
       "2 2023-01-03  느티나무 셀프BBQ_1인 수저세트     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train 로드(인코딩 폴백)\n",
    "try:\n",
    "    train = pd.read_csv('train.csv')\n",
    "except UnicodeDecodeError:\n",
    "    train = pd.read_csv('train.csv', encoding=\"cp949\")\n",
    "\n",
    "# 컬럼 표준화(필요시)\n",
    "def _canon(s):\n",
    "    return re.sub(r\"\\s+\",\"\", unicodedata.normalize(\"NFKC\", str(s).replace(\"\\ufeff\",\"\").replace(\"\\xa0\",\" \").strip()).lower()).replace(\"_\",\"\").replace(\"-\",\"\")\n",
    "orig = list(train.columns); cmap = {c:_canon(c) for c in orig}\n",
    "date_alias   = {_canon(x) for x in [\"영업일자\",\"일자\",\"날짜\",\"date\"]}\n",
    "key_single   = {_canon(x) for x in [\"영업장명_메뉴명\",\"영업장명메뉴명\",\"key\",\"메뉴키\"]}\n",
    "store_alias  = {_canon(x) for x in [\"영업장명\",\"매장명\",\"지점명\",\"점포명\",\"매장\",\"영업장\"]}\n",
    "menu_alias   = {_canon(x) for x in [\"메뉴명\",\"상품명\",\"제품명\",\"메뉴\"]}\n",
    "targ_alias   = {_canon(x) for x in [\"매출수량\",\"판매수량\",\"수량\",\"qty\",\"판매량\"]}\n",
    "\n",
    "\n",
    "date_col   = next((c for c in orig if cmap[c] in date_alias), None)\n",
    "target_col = next((c for c in orig if cmap[c] in targ_alias), None)\n",
    "key_col    = next((c for c in orig if cmap[c] in key_single), None)\n",
    "if key_col is None:\n",
    "    store_col = next((c for c in orig if cmap[c] in store_alias), None)\n",
    "    menu_col  = next((c for c in orig if cmap[c] in menu_alias ), None)\n",
    "    train[KEY] = train[store_col].astype(str).str.strip() + \"_\" + train[menu_col].astype(str).str.strip()\n",
    "else:\n",
    "    if key_col != KEY: train = train.rename(columns={key_col:KEY})\n",
    "if date_col != DATE:  train = train.rename(columns={date_col:DATE})\n",
    "if target_col != TARGET: train = train.rename(columns={target_col:TARGET})\n",
    "\n",
    "# 타입 정리\n",
    "train[DATE] = to_datetime_norm(train[DATE])\n",
    "train[TARGET] = pd.to_numeric(train[TARGET], errors=\"coerce\").clip(lower=0)\n",
    "\n",
    "print(train.shape, \"keys:\", train[KEY].nunique(), \"기간:\", train[DATE].min().date(), \"→\", train[DATE].max().date())\n",
    "train.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba4056f7",
   "metadata": {
    "id": "ba4056f7"
   },
   "outputs": [],
   "source": [
    "# weather_m는 이미 read_csv됨\n",
    "norm = lambda s: pd.to_datetime(s, errors=\"coerce\").dt.normalize()\n",
    "w = weather_m.rename(columns={\"일시\": DATE}).copy()\n",
    "w[DATE] = norm(w[DATE])\n",
    "# 컬럼 자동 탐색(최고/평균 + 기온 포함)\n",
    "col_tmax = next(c for c in w.columns if (\"최고\" in c and \"기온\" in c))\n",
    "col_tavg = next(c for c in w.columns if (\"평균\" in c and \"기온\" in c))\n",
    "w_day = (w[[DATE, col_tmax, col_tavg]]\n",
    "         .groupby(DATE, as_index=False).mean(numeric_only=True)\n",
    "         .rename(columns={col_tmax:\"wx_tmax\", col_tavg:\"wx_tavg\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91b04032-5272-42ce-8fc0-571e74235134",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = group_m.copy()\n",
    "g[DATE] = norm(g[DATE])\n",
    "\n",
    "# 겨울 시즌 플래그\n",
    "winter_m = g[[DATE]].drop_duplicates().copy()\n",
    "winter_m[DATE] = norm(winter_m[DATE])\n",
    "\n",
    "winter_m[\"month\"] = winter_m[DATE].dt.month\n",
    "winter_m[\"is_ski_season\"] = winter_m[\"month\"].isin([12,1,2]).astype(int)\n",
    "    \n",
    "# 시즌 상대적 위치 (단일 시즌 기준)\n",
    "season_mask = winter_m[\"is_ski_season\"] == 1\n",
    "if season_mask.any():\n",
    "    season_start = winter_m.loc[season_mask, DATE].min()\n",
    "    season_end   = winter_m.loc[season_mask, DATE].max()\n",
    "    season_len   = (season_end - season_start).days + 1\n",
    "    winter_m[\"day_of_season\"] = (\n",
    "        (winter_m[DATE] - season_start).dt.days / season_len\n",
    "    ).where(season_mask, 0.0)\n",
    "else:\n",
    "    winter_m[\"day_of_season\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad4b6f7d-5f43-41a1-b009-c498c52bbbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_m 기준으로 is_forest_event 생성\n",
    "g = group_m.rename(columns={\"영업일자\": DATE}).copy()\n",
    "g[DATE] = pd.to_datetime(g[DATE]).dt.normalize()\n",
    "\n",
    "# 카페테리아 + 포레스트릿 합산\n",
    "col_a = next(c for c in g.columns if \"카페테리아\" in c)\n",
    "col_b = next(c for c in g.columns if \"포레스트릿\" in c)\n",
    "g[\"cf_sum\"] = g[col_a] + g[col_b]\n",
    "\n",
    "# 이진화\n",
    "forest_m = (g[[DATE, \"cf_sum\"]]\n",
    "            .groupby(DATE, as_index=False).max(numeric_only=True))\n",
    "forest_m[\"is_forest_event\"] = (forest_m[\"cf_sum\"] > 0).astype(int)\n",
    "forest_m = forest_m[[DATE, \"is_forest_event\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lvQW4WmfHtKf",
   "metadata": {
    "id": "lvQW4WmfHtKf"
   },
   "source": [
    "## 2. 전처리\n",
    "- 평일 공휴일 세트 구성(train+test 범위)\n",
    "- 평일 공휴일 급등 클램프(train만)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "FO48VohYHtKf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "id": "FO48VohYHtKf",
    "outputId": "a8784bd2-2ff1-4e8d-a232-929a340947d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOL_WEEKDAY_SET size: 39\n",
      "train_pre: (88844, 3) 기간: 2023-01-01 → 2024-06-15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영업일자</th>\n",
       "      <th>영업장명_메뉴명</th>\n",
       "      <th>매출수량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        영업일자            영업장명_메뉴명  매출수량\n",
       "0 2023-01-01  느티나무 셀프BBQ_1인 수저세트   0.0\n",
       "1 2023-01-02  느티나무 셀프BBQ_1인 수저세트   0.0\n",
       "2 2023-01-03  느티나무 셀프BBQ_1인 수저세트   0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test 캘린더 로드\n",
    "test_files = sorted(glob.glob('test/TEST_*.csv'))\n",
    "test_list = []\n",
    "for p in test_files:\n",
    "    try:\n",
    "        t = pd.read_csv(p)\n",
    "    except UnicodeDecodeError:\n",
    "        t = pd.read_csv(p, encoding=\"cp949\")\n",
    "    # 표준 가정: DATE, KEY, TARGET 이름 동일 혹은 위에서 감지 로직 재사용 필요시 동일 처리 가능\n",
    "    if DATE not in t.columns:\n",
    "        # 간단 치환(대회 제공 포맷 가정). 필요시 수동 수정.\n",
    "        pass\n",
    "    t[DATE] = to_datetime_norm(t[DATE])\n",
    "    test_list.append(t)\n",
    "\n",
    "# HOL_WEEKDAY_SET 구성\n",
    "dmin = min([train[DATE].min()] + [t[DATE].min() for t in test_list])\n",
    "dmax = max([train[DATE].max()] + [t[DATE].max() for t in test_list]) + pd.Timedelta(days=PREDICT+14)\n",
    "\n",
    "manual_days = pd.to_datetime([\n",
    "    \"2023-01-23\",\"2023-01-24\",\"2023-03-01\",\"2023-05-05\",\"2023-05-29\",\"2023-06-06\",\"2023-08-15\",\n",
    "    \"2023-09-28\",\"2023-09-29\",\"2023-10-02\",\"2023-10-03\",\"2023-10-09\",\"2023-12-25\",\n",
    "    \"2024-01-01\",\"2024-02-09\",\"2024-02-12\",\"2024-03-01\",\"2024-04-10\",\"2024-05-06\",\"2024-05-15\",\n",
    "    \"2024-06-06\",\"2024-08-15\",\"2024-09-16\",\"2024-09-17\",\"2024-09-18\",\"2024-10-01\",\"2024-10-03\",\"2024-10-09\",\"2024-12-25\",\n",
    "    \"2025-01-01\",\"2025-01-27\",\"2025-01-28\",\"2025-01-29\",\"2025-01-30\",\"2025-03-03\",\n",
    "    \"2025-05-05\",\"2025-05-06\",\"2025-06-03\",\"2025-06-06\",\"2025-08-15\",\"2025-10-03\",\"2025-10-09\",\"2025-12-25\",\n",
    "    \"2026-01-01\"\n",
    "]).normalize()\n",
    "\n",
    "try:\n",
    "    import holidays as _hol\n",
    "    years = sorted({d.year for d in pd.date_range(dmin, dmax, freq=\"D\")})\n",
    "    kr = _hol.KR(years=years)\n",
    "    hol = pd.DatetimeIndex([pd.Timestamp(k) for k in kr]).normalize()\n",
    "    hol = pd.DatetimeIndex(sorted(set(hol) | set(manual_days)))\n",
    "except Exception:\n",
    "    hol = pd.DatetimeIndex(sorted(set(manual_days)))\n",
    "hol = hol[(hol>=dmin)&(hol<=dmax)]\n",
    "HOL_WEEKDAY_SET = set(hol[hol.dayofweek<5])\n",
    "print(\"HOL_WEEKDAY_SET size:\", len(HOL_WEEKDAY_SET))\n",
    "\n",
    "# 평일 공휴일 급등 완화(train만)\n",
    "x = train.copy().sort_values([KEY, DATE]).reset_index(drop=True)\n",
    "x[\"dow\"] = x[DATE].dt.dayofweek\n",
    "x[\"is_nonhol_weekday\"] = ((x[\"dow\"]<5) & (~x[DATE].isin(HOL_WEEKDAY_SET))).astype(int)\n",
    "x[\"is_hol_wk\"]         = (x[DATE].isin(HOL_WEEKDAY_SET)).astype(int)\n",
    "x[\"__val__\"] = x[TARGET].astype(float)\n",
    "\n",
    "outs = []\n",
    "for k, g in x.groupby(KEY, sort=False):\n",
    "    if (BRUNCH_WD in str(k)) or (BRUNCH_WE in str(k)):\n",
    "        outs.append(g); continue\n",
    "    g = g.copy()\n",
    "    g[\"med_wd_dow\"] = np.nan\n",
    "    for d in range(5):\n",
    "        idx = (g[\"dow\"]==d) & (g[\"is_nonhol_weekday\"]==1)\n",
    "        s = g.loc[idx,\"__val__\"]\n",
    "        med = s.shift(1).rolling(window=4, min_periods=2).median()\n",
    "        g.loc[idx,\"med_wd_dow\"] = med.values\n",
    "    is_metric_target = ((\"단체\" in str(k)) or (str(k) in EXTRA_GROUP_KEYS)) and not ((BRUNCH_WD in str(k)) or (BRUNCH_WE in str(k)))\n",
    "    if is_metric_target:\n",
    "        thr_up = (1.0+0.25)*g[\"med_wd_dow\"]\n",
    "        adj = ((g[\"is_hol_wk\"]==1)&np.isfinite(g[\"med_wd_dow\"])&(g[\"__val__\"]>thr_up))\n",
    "        g.loc[adj,\"__val__\"] = np.maximum(0.0, np.round((1.0+0.10)*g.loc[adj,\"med_wd_dow\"]))\n",
    "    g = g.drop(columns=[\"med_wd_dow\"])\n",
    "    outs.append(g)\n",
    "\n",
    "train_pre = pd.concat(outs, axis=0).drop(columns=[\"dow\",\"is_nonhol_weekday\",\"is_hol_wk\"])\n",
    "train_pre[TARGET] = train_pre[\"__val__\"].astype(float).clip(lower=0)\n",
    "train_pre = train_pre.drop(columns=\"__val__\").sort_values([KEY, DATE]).reset_index(drop=True)\n",
    "\n",
    "print(\"train_pre:\", train_pre.shape, \"기간:\", train_pre[DATE].min().date(), \"→\", train_pre[DATE].max().date())\n",
    "train_pre.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d385386a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "d385386a",
    "outputId": "c9743c71-5618-4d25-c8dd-6ad85d24e4ae"
   },
   "outputs": [],
   "source": [
    "train_pre = train_pre.merge(w_day, on=DATE, how=\"left\")\n",
    "train_pre = train_pre.merge(winter_m, on=DATE, how=\"left\")\n",
    "train_pre = train_pre.merge(forest_m, on=DATE, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "Uak8NTegbSOA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Uak8NTegbSOA",
    "outputId": "8d3e1047-5f84-4a80-d1c1-5d1fd3aa774b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영업일자</th>\n",
       "      <th>영업장명_메뉴명</th>\n",
       "      <th>매출수량</th>\n",
       "      <th>wx_tmax</th>\n",
       "      <th>wx_tavg</th>\n",
       "      <th>month</th>\n",
       "      <th>is_ski_season</th>\n",
       "      <th>day_of_season</th>\n",
       "      <th>is_forest_event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        영업일자            영업장명_메뉴명  매출수량  wx_tmax  wx_tavg  month  \\\n",
       "0 2023-01-01  느티나무 셀프BBQ_1인 수저세트   0.0      5.5     -1.7      1   \n",
       "1 2023-01-02  느티나무 셀프BBQ_1인 수저세트   0.0      1.3     -4.1      1   \n",
       "2 2023-01-03  느티나무 셀프BBQ_1인 수저세트   0.0      1.7     -6.2      1   \n",
       "3 2023-01-04  느티나무 셀프BBQ_1인 수저세트   0.0      3.9     -3.8      1   \n",
       "4 2023-01-05  느티나무 셀프BBQ_1인 수저세트   0.0      2.3     -5.3      1   \n",
       "\n",
       "   is_ski_season  day_of_season  is_forest_event  \n",
       "0              1       0.000000                0  \n",
       "1              1       0.002353                0  \n",
       "2              1       0.004706                1  \n",
       "3              1       0.007059                1  \n",
       "4              1       0.009412                1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pre.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eNGkmo3kHtKi",
   "metadata": {
    "id": "eNGkmo3kHtKi"
   },
   "source": [
    "## 3. 피처 추가\n",
    "- 랙·롤링·EWM·푸리에·미래 캘린더\n",
    "- KEY 인코딩은 학습에서만 fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6afed112",
   "metadata": {
    "id": "6afed112"
   },
   "outputs": [],
   "source": [
    "room_m = pd.read_csv('TRAIN_room.csv')\n",
    "room_type = pd.read_csv('room_type.csv')\n",
    "\n",
    "room_dict = {}\n",
    "for _type, _num in zip(room_type['객실타입'], room_type['기준인원']):\n",
    "    room_dict.update({_type:_num})\n",
    "\n",
    "today_num = []\n",
    "for i in range(len(room_m)):\n",
    "    a = room_m.iloc[i]\n",
    "    _sum = 0\n",
    "    for _type in room_dict.keys():\n",
    "        _sum += a[_type]*room_dict[_type]\n",
    "\n",
    "    today_num.append(_sum)\n",
    "\n",
    "room_m['총방문객수'] = today_num\n",
    "\n",
    "# df2의 영업일자를 datetime으로 변환\n",
    "room_m['영업일자'] = pd.to_datetime(room_m['영업일자'])\n",
    "\n",
    "train_pre = train_pre.merge(room_m[[DATE, '총방문객수']], on=DATE, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "nj8WzPz2HtKj",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "nj8WzPz2HtKj",
    "outputId": "915115fd-a288-41e9-dfe7-cc590bda0749"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainF: (68480, 69) features: 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>key_encoded</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>is_quarter_end</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>rolling_mean_7</th>\n",
       "      <th>rolling_std_7</th>\n",
       "      <th>...</th>\n",
       "      <th>dow_h7</th>\n",
       "      <th>is_weekend_h7</th>\n",
       "      <th>is_wkhol_h7</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "      <th>target_3</th>\n",
       "      <th>target_4</th>\n",
       "      <th>target_5</th>\n",
       "      <th>target_6</th>\n",
       "      <th>target_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>3.023716</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>3.023716</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>3.147183</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  dayofweek key_encoded  day  dayofyear  is_month_end  is_quarter_end  \\\n",
       "0      1          6           0   22         22             0               0   \n",
       "1      1          0           0   23         23             0               0   \n",
       "2      1          1           0   24         24             0               0   \n",
       "\n",
       "   is_weekend  rolling_mean_7  rolling_std_7  ...  dow_h7  is_weekend_h7  \\\n",
       "0           1        1.142857       3.023716  ...       6              1   \n",
       "1           0        1.142857       3.023716  ...       0              0   \n",
       "2           0        1.714286       3.147183  ...       1              0   \n",
       "\n",
       "   is_wkhol_h7  target_1  target_2  target_3  target_4  target_5  target_6  \\\n",
       "0            0       4.0       2.0       0.0       0.0       8.0       0.0   \n",
       "1            0       2.0       0.0       0.0       8.0       0.0       8.0   \n",
       "2            0       0.0       0.0       8.0       0.0       8.0       0.0   \n",
       "\n",
       "   target_7  \n",
       "0       8.0  \n",
       "1       0.0  \n",
       "2       4.0  \n",
       "\n",
       "[3 rows x 66 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습용 피처 생성\n",
    "df = train_pre.copy()\n",
    "df = df.sort_values([KEY, DATE]).reset_index(drop=True)\n",
    "\n",
    "df[\"month\"] = df[DATE].dt.month\n",
    "df[\"dayofweek\"] = df[DATE].dt.dayofweek\n",
    "df[\"day\"] = df[DATE].dt.day\n",
    "df[\"dayofyear\"] = df[DATE].dt.dayofyear\n",
    "df[\"is_month_end\"] = df[DATE].dt.is_month_end.astype(int)\n",
    "df[\"is_quarter_end\"] = df[DATE].dt.is_quarter_end.astype(int)\n",
    "df[\"is_weekend\"] = (df[\"dayofweek\"]>=5).astype(int)\n",
    "\n",
    "# 미래 캘린더\n",
    "for h in range(1, PREDICT+1):\n",
    "    dth = df[DATE] + pd.to_timedelta(h, unit=\"D\")\n",
    "    df[f\"dow_h{h}\"]        = dth.dt.dayofweek\n",
    "    df[f\"is_weekend_h{h}\"] = (df[f\"dow_h{h}\"]>=5).astype(int)\n",
    "    df[f\"is_wkhol_h{h}\"]   = dth.isin(pd.DatetimeIndex(HOL_WEEKDAY_SET)).astype(int)\n",
    "\n",
    "# 랙/롤링\n",
    "for lag in [7,14,21]:\n",
    "    df[f\"lag_{lag}\"] = df.groupby(KEY)[TARGET].shift(lag)\n",
    "for w in [7,14]:\n",
    "    df[f\"rolling_mean_{w}\"]   = df.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(w).mean())\n",
    "    df[f\"rolling_std_{w}\"]    = df.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(w).std())\n",
    "    df[f\"rolling_median_{w}\"] = df.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(w).median())\n",
    "for lag in [1,2,3,4,5,6]:\n",
    "    df[f\"lag_{lag}\"] = df.groupby(KEY)[TARGET].shift(lag)\n",
    "\n",
    "df[\"rolling_mean_21\"] = df.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(21).mean())\n",
    "df[\"ratio_mean7_21\"]  = df[\"rolling_mean_7\"]/df[\"rolling_mean_21\"]\n",
    "df[\"ratio_mean14_21\"] = df[\"rolling_mean_14\"]/df[\"rolling_mean_21\"]\n",
    "\n",
    "def _slope_raw(v):\n",
    "    m = np.isfinite(v); v = v[m]; n=v.size\n",
    "    if n<2: return np.nan\n",
    "    x = np.arange(n, dtype=float); xm, ym = x.mean(), v.mean()\n",
    "    denom = ((x-xm)**2).sum();\n",
    "    if denom==0: return 0.0\n",
    "    return float(((x-xm)*(v-ym)).sum()/denom)\n",
    "\n",
    "df[\"slope_7\"]  = df.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(7).apply(_slope_raw, raw=True))\n",
    "df[\"slope_14\"] = df.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(14).apply(_slope_raw, raw=True))\n",
    "\n",
    "# 무판매 장기구간 플래그\n",
    "def _flag_long_zero_block(g, min_days):\n",
    "    is_zero = (g[TARGET]==0).astype(int)\n",
    "    block_id = (is_zero != is_zero.shift()).cumsum()\n",
    "    block_len = is_zero.groupby(block_id).transform(\"sum\")\n",
    "    return ((is_zero==1)&(block_len>=min_days)).astype(int)\n",
    "df[\"is_long_zero_block\"] = df.groupby(KEY, sort=False).apply(lambda g: _flag_long_zero_block(g, NON_SELLING_MIN_DAYS)).reset_index(level=0, drop=True).astype(int)\n",
    "\n",
    "# EWM\n",
    "df[\"ewm_mean_7\"] = df.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).ewm(span=7, adjust=False, min_periods=2).mean())\n",
    "\n",
    "# 요일 Fourier\n",
    "x_dow = df[\"dayofweek\"].astype(float)\n",
    "df[\"dow_sin\"] = np.sin(2*np.pi*x_dow/7.0); df[\"dow_cos\"] = np.cos(2*np.pi*x_dow/7.0)\n",
    "\n",
    "# KEY 인코딩\n",
    "cats = pd.Index(sorted(df[KEY].astype(str).unique()))\n",
    "key2id = {k:i for i,k in enumerate(cats)}\n",
    "df[\"key_encoded\"] = df[KEY].astype(str).map(key2id).astype(\"category\")\n",
    "\n",
    "# 타깃 시프팅\n",
    "for i in range(1, PREDICT+1):\n",
    "    df[f\"target_{i}\"] = df.groupby(KEY)[TARGET].shift(-i)\n",
    "df_trainF = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# 피처 목록\n",
    "feat_cols = [\n",
    "    \"month\",\"dayofweek\",\"key_encoded\",\"day\",\"dayofyear\",\"is_month_end\",\"is_quarter_end\",\"is_weekend\",\n",
    "    \"rolling_mean_7\",\"rolling_std_7\",\"rolling_median_7\",\n",
    "    \"rolling_mean_14\",\"rolling_std_14\",\"rolling_median_14\",\n",
    "    \"rolling_mean_21\",\"ratio_mean7_21\",\"ratio_mean14_21\",\n",
    "    \"slope_7\",\"slope_14\",\"ewm_mean_7\",\"dow_sin\",\"dow_cos\",\"is_long_zero_block\",\"wx_tmax\",\"wx_tavg\",\"총방문객수\",'is_ski_season', 'day_of_season', 'is_forest_event'\n",
    "] + [c for c in df.columns if re.match(r\"^lag_\\d+$\", c)] + [c for c in df.columns if re.match(r\"^(dow_h\\d|is_weekend_h\\d|is_wkhol_h\\d)$\", c)]\n",
    "\n",
    "print(\"TrainF:\", df_trainF.shape, \"features:\", len(feat_cols))\n",
    "df_trainF[feat_cols + [f\"target_{i}\" for i in range(1,PREDICT+1)]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2832ba1e",
   "metadata": {
    "editable": true,
    "id": "2832ba1e",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === 리더보드 점수용 지표 ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _mask_nonzero(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, float)\n",
    "    y_pred = np.asarray(y_pred, float)\n",
    "    m = (y_true != 0)\n",
    "    return y_true[m], y_pred[m]\n",
    "\n",
    "def smape_frac(y_true, y_pred):\n",
    "    yt, yp = _mask_nonzero(y_true, y_pred)\n",
    "    if yt.size == 0: return np.nan\n",
    "    denom = (np.abs(yt) + np.abs(yp))\n",
    "    num = 2.0 * np.abs(yp - yt)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        val = np.where(denom > 0, num / denom, 0.0)\n",
    "    return float(np.mean(val))\n",
    "\n",
    "def mae_over_mean(y_true, y_pred):\n",
    "    yt, yp = _mask_nonzero(y_true, y_pred)\n",
    "    if yt.size == 0: return np.nan\n",
    "    mae = np.mean(np.abs(yp - yt))\n",
    "    ybar = np.mean(yt)\n",
    "    return float(mae / ybar) if ybar != 0 else np.nan\n",
    "\n",
    "def rmse_over_mean(y_true, y_pred):\n",
    "    yt, yp = _mask_nonzero(y_true, y_pred)\n",
    "    if yt.size == 0: return np.nan\n",
    "    rmse = np.sqrt(np.mean((yp - yt)**2))\n",
    "    ybar = np.mean(yt)\n",
    "    return float(rmse / ybar) if ybar != 0 else np.nan\n",
    "\n",
    "def r2_pearson(y_true, y_pred):\n",
    "    yt, yp = _mask_nonzero(y_true, y_pred)\n",
    "    if yt.size < 2: return np.nan\n",
    "    corr = np.corrcoef(yt, yp)[0,1]\n",
    "    if np.isnan(corr): return np.nan\n",
    "    return float(corr**2)\n",
    "\n",
    "def leaderboard_score(y_true, y_pred):\n",
    "    a = smape_frac(y_true, y_pred)\n",
    "    b = mae_over_mean(y_true, y_pred)\n",
    "    c = rmse_over_mean(y_true, y_pred)\n",
    "    d = r2_pearson(y_true, y_pred)\n",
    "    if np.any(np.isnan([a,b,c,d])): return np.nan\n",
    "    return 0.25 * ((1 - a/2.0) + (1 - min(1.0, b)) + (1 - min(1.0, c)) + d)\n",
    "\n",
    "# === WindowCV folds 생성 ===\n",
    "def make_window_cv(dates, input_window=INPUT_WINDOW_DAYS, horizon=PREDICT,\n",
    "                   n_folds=5, stride=7, gap=0):\n",
    "    \"\"\"\n",
    "    return: list of (train_end, valid_start, valid_end)\n",
    "    \"\"\"\n",
    "    dates = np.array(sorted(dates))\n",
    "    last_idx = len(dates) - 1\n",
    "    out = []\n",
    "    end_idxs = list(range(last_idx, input_window + horizon - 1, -stride))[:n_folds]\n",
    "    for ve in end_idxs:\n",
    "        vs = ve - (horizon - 1)\n",
    "        te = vs - (gap + 1)\n",
    "        ts = te - (input_window - 1)\n",
    "        if ts < 0:\n",
    "            continue\n",
    "        out.append((dates[te], dates[vs], dates[ve]))\n",
    "    out = sorted(out, key=lambda x: x[1])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ROxw8CEuHtKn",
   "metadata": {
    "id": "ROxw8CEuHtKn"
   },
   "outputs": [],
   "source": [
    "# === Tweedie p 앙상블 설정 ===\n",
    "P_LIST = [1.1, 1.2, 1.3, 1.4]      # 필요시 수정\n",
    "ENSEMBLE_MODE = \"softmax\"          # [\"equal\", \"softmax\", \"linear_pos\"]\n",
    "TAU = 0.5                          # softmax 온도(작을수록 상위 가중 ↑)\n",
    "\n",
    "def fit_multiout_with_p(X, y, p, seed=SEED_BASE, n_estim=N_ESTIMATORS_FULL):\n",
    "    base = lgb.LGBMRegressor(\n",
    "        n_estimators=n_estim, learning_rate=0.04, num_leaves=63,\n",
    "        feature_fraction=0.8, bagging_fraction=0.8, bagging_freq=1,\n",
    "        lambda_l1=0.1, lambda_l2=0.1, random_state=seed,\n",
    "        objective=\"tweedie\", metric=\"mae\", tweedie_variance_power=float(p), verbose=-1\n",
    "    )\n",
    "    m = MultiOutputRegressor(base)\n",
    "    X_ = X.copy()\n",
    "    for c in (\"key_encoded\",\"month\",\"dayofweek\"):\n",
    "        if c in X_.columns: X_[c] = X_[c].astype(\"category\")\n",
    "    m.fit(X_, y, categorical_feature=[c for c in (\"key_encoded\",\"month\",\"dayofweek\") if c in X_.columns])\n",
    "    return m\n",
    "\n",
    "def make_weights_from_scores(scores_dict, mode=\"softmax\", tau=0.5):\n",
    "    # scores_dict: {p: mean_LB}\n",
    "    ps = list(scores_dict.keys())\n",
    "    s  = np.array([scores_dict[p] for p in ps], float)\n",
    "    if not np.all(np.isfinite(s)):  # 결측 있으면 균등\n",
    "        w = np.ones_like(s)/len(s); return dict(zip(ps, w))\n",
    "    if mode == \"equal\":\n",
    "        w = np.ones_like(s)/len(s)\n",
    "    elif mode == \"softmax\":\n",
    "        x = s / max(1e-9, tau)\n",
    "        x -= x.max()\n",
    "        w = np.exp(x); w /= w.sum()\n",
    "    elif mode == \"linear_pos\":\n",
    "        s = s - s.min()\n",
    "        if s.sum() <= 0: w = np.ones_like(s)/len(s)\n",
    "        else: w = s / s.sum()\n",
    "    else:\n",
    "        w = np.ones_like(s)/len(s)\n",
    "    return dict(zip(ps, w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dbd52cb",
   "metadata": {
    "id": "2dbd52cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folds: [(datetime.date(2024, 5, 4), datetime.date(2024, 5, 5), datetime.date(2024, 5, 11)), (datetime.date(2024, 5, 11), datetime.date(2024, 5, 12), datetime.date(2024, 5, 18)), (datetime.date(2024, 5, 18), datetime.date(2024, 5, 19), datetime.date(2024, 5, 25)), (datetime.date(2024, 5, 25), datetime.date(2024, 5, 26), datetime.date(2024, 6, 1)), (datetime.date(2024, 6, 1), datetime.date(2024, 6, 2), datetime.date(2024, 6, 8))]\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "\n",
      "[Tweedie p=1.1]\n",
      "   fold     sMAPE  MAE/mean  RMSE/mean        R2        LB\n",
      "0     1  0.600130  0.490013   1.149619  0.670733  0.470164\n",
      "1     2  0.603181  0.454979   1.106971  0.714375  0.489451\n",
      "2     3  0.603111  0.468833   1.267030  0.630096  0.464927\n",
      "3     4  0.593212  0.484095   1.318344  0.616080  0.458845\n",
      "4     5  0.623773  0.537284   1.430399  0.516643  0.416868\n",
      "mean LB: 0.4600509093178591\n",
      "\n",
      "[Tweedie p=1.2]\n",
      "   fold     sMAPE  MAE/mean  RMSE/mean        R2        LB\n",
      "0     1  0.607655  0.482349   1.131941  0.684546  0.474592\n",
      "1     2  0.610634  0.451829   1.099680  0.709800  0.488164\n",
      "2     3  0.610046  0.468389   1.278247  0.619612  0.461550\n",
      "3     4  0.601855  0.480648   1.306077  0.622360  0.460196\n",
      "4     5  0.631821  0.540892   1.452991  0.499389  0.410647\n",
      "mean LB: 0.4590297132995594\n",
      "\n",
      "[Tweedie p=1.3]\n",
      "   fold     sMAPE  MAE/mean  RMSE/mean        R2        LB\n",
      "0     1  0.622704  0.496210   1.165497  0.664510  0.464237\n",
      "1     2  0.622246  0.455507   1.114802  0.711121  0.486123\n",
      "2     3  0.622643  0.471577   1.283742  0.614708  0.457952\n",
      "3     4  0.609154  0.483261   1.320632  0.617892  0.457513\n",
      "4     5  0.646300  0.545897   1.467143  0.493270  0.406056\n",
      "mean LB: 0.45437624761285933\n",
      "\n",
      "[Tweedie p=1.4]\n",
      "   fold     sMAPE  MAE/mean  RMSE/mean        R2        LB\n",
      "0     1  0.634387  0.494936   1.170431  0.664913  0.463196\n",
      "1     2  0.641254  0.465798   1.147023  0.691287  0.476215\n",
      "2     3  0.634740  0.482126   1.312640  0.602493  0.450749\n",
      "3     4  0.620791  0.482168   1.312611  0.624832  0.458067\n",
      "4     5  0.661008  0.550867   1.476050  0.482879  0.400377\n",
      "mean LB: 0.449720946264598\n",
      "\n",
      "Ensemble weights by p: {1.1: 0.25212881450882146, 1.2: 0.2516143941287349, 1.3: 0.24928349979178369, 1.4: 0.24697329157065995}\n"
     ]
    }
   ],
   "source": [
    "# === WindowCV 날짜 ===\n",
    "dates_sorted = np.array(sorted(df_trainF[DATE].unique()))\n",
    "folds = make_window_cv(dates_sorted, input_window=INPUT_WINDOW_DAYS,\n",
    "                       horizon=PREDICT, n_folds=5, stride=7, gap=0)\n",
    "print(\"folds:\", [(te.date(), vs.date(), ve.date()) for te,vs,ve in folds])\n",
    "\n",
    "# === p별 CV\n",
    "cv_tables = {}\n",
    "mean_lb_by_p = {}\n",
    "\n",
    "for p in P_LIST:\n",
    "    fold_metrics = []\n",
    "    for fi, (train_end, valid_start, valid_end) in enumerate(folds, 1):\n",
    "        tr_mask = (df_trainF[DATE] <= train_end)\n",
    "        va_mask = (df_trainF[DATE] >= valid_start) & (df_trainF[DATE] <= valid_end)\n",
    "\n",
    "        trF = df_trainF.loc[tr_mask].copy()\n",
    "        vaF = df_trainF.loc[va_mask].copy()\n",
    "        if len(trF)==0 or len(vaF)==0:\n",
    "            continue\n",
    "\n",
    "        Xtr = trF[feat_cols].copy()\n",
    "        ytr = trF[[f\"target_{i}\" for i in range(1, PREDICT+1)]].copy()\n",
    "        model_cv = fit_multiout_with_p(Xtr, ytr, p=float(p), seed=SEED_BASE, n_estim=N_ESTIMATORS_FULL)\n",
    "\n",
    "        Xva = vaF[feat_cols].copy()\n",
    "        for c in (\"key_encoded\",\"month\",\"dayofweek\"):\n",
    "            if c in Xva.columns: Xva[c] = Xva[c].astype(\"category\")\n",
    "        y_pred = model_cv.predict(Xva)\n",
    "        y_true = vaF[[f\"target_{i}\" for i in range(1, PREDICT+1)]].values\n",
    "\n",
    "        a = smape_frac(y_true, y_pred)\n",
    "        b = mae_over_mean(y_true, y_pred)\n",
    "        c = rmse_over_mean(y_true, y_pred)\n",
    "        d = r2_pearson(y_true, y_pred)\n",
    "        L = leaderboard_score(y_true, y_pred)\n",
    "        fold_metrics.append({\"fold\": fi, \"sMAPE\": a, \"MAE/mean\": b, \"RMSE/mean\": c, \"R2\": d, \"LB\": L})\n",
    "\n",
    "    cv_df = pd.DataFrame(fold_metrics)\n",
    "    cv_tables[p] = cv_df\n",
    "    mean_lb_by_p[p] = float(np.nanmean(cv_df[\"LB\"])) if len(cv_df) else np.nan\n",
    "\n",
    "# 요약 출력\n",
    "for p in P_LIST:\n",
    "    dfp = cv_tables[p]\n",
    "    print(f\"\\n[Tweedie p={p}]\")\n",
    "    print(dfp)\n",
    "    print(\"mean LB:\", np.nanmean(dfp[\"LB\"]) if len(dfp) else np.nan)\n",
    "\n",
    "# p-가중치 산출\n",
    "P_WEIGHTS = make_weights_from_scores(mean_lb_by_p, mode=ENSEMBLE_MODE, tau=TAU)\n",
    "print(\"\\nEnsemble weights by p:\", P_WEIGHTS)\n",
    "\n",
    "# 제출 후처리용 라운딩 임계치 고정\n",
    "best_thr = 0.130"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GJufjHiRHtKo",
   "metadata": {
    "id": "GJufjHiRHtKo"
   },
   "source": [
    "## 5. 모델 학습(전체 학습 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ziaKP-GHtKp",
   "metadata": {
    "id": "0ziaKP-GHtKp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "fit done for all p: [1.1, 1.2, 1.3, 1.4]\n"
     ]
    }
   ],
   "source": [
    "## 5. p별 전체 학습(models_full 생성)\n",
    "models_full = {}\n",
    "X_full = df_trainF[feat_cols].copy()\n",
    "for c in (\"key_encoded\",\"month\",\"dayofweek\"):\n",
    "    if c in X_full.columns: X_full[c] = X_full[c].astype(\"category\")\n",
    "y_full = df_trainF[[f\"target_{i}\" for i in range(1, PREDICT+1)]].copy()\n",
    "\n",
    "for p in P_LIST:\n",
    "    models_full[p] = fit_multiout_with_p(X_full, y_full, p=float(p), seed=SEED_BASE, n_estim=N_ESTIMATORS_FULL)\n",
    "\n",
    "# 가중치 정규화 및 검증\n",
    "s = sum(v for v in P_WEIGHTS.values() if np.isfinite(v))\n",
    "if s <= 0 or not np.isfinite(s):\n",
    "    P_WEIGHTS = {p: 1.0/len(P_LIST) for p in P_LIST}\n",
    "else:\n",
    "    P_WEIGHTS = {p: float(w)/s for p,w in P_WEIGHTS.items()}\n",
    "assert len(models_full)>0 and abs(sum(P_WEIGHTS.values())-1)<1e-6\n",
    "print(\"fit done for all p:\", P_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FE1II-LJHtKq",
   "metadata": {
    "id": "FE1II-LJHtKq"
   },
   "source": [
    "## 6. 예측값 도출(Anchor Ensemble, K=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78e63382",
   "metadata": {
    "id": "78e63382"
   },
   "outputs": [],
   "source": [
    "# 무판매 장기구간 플래그(학습과 동일)\n",
    "def _flag_lzb(g):\n",
    "    iz = (g[TARGET] == 0).astype(int)\n",
    "    bid = (iz != iz.shift()).cumsum()\n",
    "    blen = iz.groupby(bid).transform(\"sum\")\n",
    "    return ((iz == 1) & (blen >= NON_SELLING_MIN_DAYS)).astype(int)\n",
    "# === 공용 헬퍼 ===\n",
    "def weekday_holiday_impute(df, hol_set):\n",
    "    xx = df.copy()\n",
    "    xx[\"dow\"] = xx[DATE].dt.dayofweek\n",
    "    xx[\"is_weekday\"] = (xx[\"dow\"] < 5).astype(int)\n",
    "    xx[\"is_weekday_hol\"] = xx[DATE].isin(hol_set).astype(int)\n",
    "\n",
    "    outs = []\n",
    "    for k, g in xx.groupby(KEY, sort=False):\n",
    "        g = g.sort_values(DATE).copy()\n",
    "        end_date = g[DATE].max()\n",
    "        cand = g[(g[\"is_weekday\"]==1) & (g[\"is_weekday_hol\"]==0)].copy()\n",
    "        all_weekday_zero = (cand[TARGET].sum()==0)\n",
    "\n",
    "        def _wmean(vals, dates, end_date, decay=0.90, lastweek_window=7, boost=0.50):\n",
    "            if len(vals)==0: return np.nan\n",
    "            vals = np.asarray(vals,float); dates = pd.to_datetime(dates)\n",
    "            delta = (end_date - dates).days.astype(float)\n",
    "            w = decay ** delta\n",
    "            w = np.where(dates >= end_date - pd.Timedelta(days=lastweek_window-1), w*(1+boost), w)\n",
    "            return float(np.sum(w*vals)/np.sum(w))\n",
    "\n",
    "        for idx, row in g.loc[(g[\"is_weekday\"]==1) & (g[\"is_weekday_hol\"]==1)].iterrows():\n",
    "            if all_weekday_zero:\n",
    "                g.at[idx, TARGET] = 0; continue\n",
    "            pool = cand[cand[\"dow\"]==int(row[\"dow\"])]\n",
    "            base = _wmean(pool[TARGET].values, pool[DATE].values, end_date) if len(pool) else \\\n",
    "                   _wmean(cand[TARGET].values, cand[DATE].values, end_date)\n",
    "            t7 = row[DATE] - pd.Timedelta(days=7)\n",
    "            prev = g[(g[DATE]==t7) & (g[\"is_weekday\"]==1) & (g[\"is_weekday_hol\"]==0)]\n",
    "            val_t7 = float(prev[TARGET].iloc[0]) if len(prev)==1 else np.nan\n",
    "            if np.isfinite(base):\n",
    "                y_hat = base if not np.isfinite(val_t7) else 0.65*base + 0.35*val_t7\n",
    "                g.at[idx, TARGET] = int(max(0, round(y_hat)))\n",
    "            else:\n",
    "                g.at[idx, TARGET] = 0\n",
    "        outs.append(g)\n",
    "    return pd.concat(outs, axis=0).drop(columns=[\"dow\",\"is_weekday\",\"is_weekday_hol\"])\n",
    "\n",
    "def spike_clamp(df, hol_set):\n",
    "    x2 = df.copy()\n",
    "    x2[\"dow\"] = x2[DATE].dt.dayofweek\n",
    "    x2[\"is_nonhol_weekday\"] = ((x2[\"dow\"]<5) & (~x2[DATE].isin(hol_set))).astype(int)\n",
    "    x2[\"is_hol_wk\"] = x2[DATE].isin(hol_set).astype(int)\n",
    "\n",
    "    outs = []\n",
    "    for k, g in x2.groupby(KEY, sort=False):\n",
    "        if (BRUNCH_WD in str(k)) or (BRUNCH_WE in str(k)):\n",
    "            outs.append(g); continue\n",
    "        g = g.copy()\n",
    "        idx = (g[\"is_nonhol_weekday\"]==1)\n",
    "        s = g.loc[idx, TARGET].astype(float)\n",
    "        med = s.shift(1).rolling(window=4, min_periods=2).median()\n",
    "        g.loc[idx, \"med_wd_dow\"] = med.values\n",
    "        is_metric_target = ((\"단체\" in str(k)) or (str(k) in EXTRA_GROUP_KEYS))\n",
    "        if is_metric_target:\n",
    "            thr_up = 1.25 * g[\"med_wd_dow\"]\n",
    "            adj = (g[\"is_hol_wk\"]==1) & np.isfinite(g[\"med_wd_dow\"]) & (g[TARGET] > thr_up)\n",
    "            g.loc[adj, TARGET] = np.maximum(0.0, np.round(1.10 * g.loc[adj, \"med_wd_dow\"]))\n",
    "        outs.append(g.drop(columns=[\"med_wd_dow\"]))\n",
    "    return pd.concat(outs, axis=0).drop(columns=[\"dow\",\"is_nonhol_weekday\",\"is_hol_wk\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "544b9d96",
   "metadata": {
    "editable": true,
    "id": "544b9d96",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _read_csv_robust(p):\n",
    "    try:    return pd.read_csv(p)\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(p, encoding=\"cp949\")\n",
    "\n",
    "test_wday = {}\n",
    "for wp in sorted(glob.glob(\"test/meta/TEST_weather_*.csv\")):\n",
    "    wid = os.path.splitext(os.path.basename(wp))[0].split(\"_\")[-1]  # \"00\"~\"09\"\n",
    "    fid = f\"TEST_{wid}\"  # TEST_00 …\n",
    "\n",
    "    w = _read_csv_robust(wp).rename(columns={\"일시\": DATE})\n",
    "    w[DATE] = to_datetime_norm(w[DATE])\n",
    "    col_tmax = next(c for c in w.columns if (\"최고\" in c and \"기온\" in c))\n",
    "    col_tavg = next(c for c in w.columns if (\"평균\" in c and \"기온\" in c))\n",
    "    w_day_test = (w[[DATE, col_tmax, col_tavg]]\n",
    "                  .groupby(DATE, as_index=False).mean(numeric_only=True)\n",
    "                  .rename(columns={col_tmax:\"wx_tmax\", col_tavg:\"wx_tavg\"}))\n",
    "    test_wday[fid] = w_day_test\n",
    "\n",
    "_w_fallback = pd.DataFrame({DATE: pd.to_datetime([]), \"wx_tmax\": [], \"wx_tavg\": []})\n",
    "\n",
    "def add_weather_feats(df, wday):\n",
    "    return df.merge(wday, on=DATE, how=\"left\")  # wday는 (DATE, wx_tmax, wx_tavg)\n",
    "\n",
    "test_room = {}\n",
    "for wp in sorted(glob.glob(\"test/meta/TEST_room_*.csv\")):# wp : test/meta/TEST_room_09.csv\n",
    "    wid = os.path.splitext(os.path.basename(wp))[0].split(\"_\")[-1]  # \"00\"~\"09\"\n",
    "    fid = f\"TEST_{wid}\"  # TEST_00 …\n",
    "\n",
    "    w = _read_csv_robust(wp).rename(columns={\"일시\": DATE}) # room_m data\n",
    "    w[DATE] = to_datetime_norm(w[DATE])\n",
    "\n",
    "    today_num = []\n",
    "\n",
    "    for i in range(len(w)):\n",
    "        a = w.iloc[i]\n",
    "        _sum = 0\n",
    "        for _type in room_dict.keys():\n",
    "            _sum += a[_type]*room_dict[_type]\n",
    "\n",
    "        today_num.append(_sum)\n",
    "\n",
    "    w['총방문객수'] = today_num\n",
    "\n",
    "    test_room.update({fid:w})\n",
    "\n",
    "_room_fallback = pd.DataFrame({DATE: pd.to_datetime([]), \"총방문객수\": []})\n",
    "\n",
    "def add_room_feats(df, room):\n",
    "    return df.merge(room, on=DATE, how=\"left\")  # room은 (DATE, 총방문객수)\n",
    "\n",
    "def to_datetime_norm(s):\n",
    "    return pd.to_datetime(s, errors=\"coerce\").dt.normalize()\n",
    "\n",
    "test_group = {}\n",
    "\n",
    "for gp in sorted(glob.glob(\"test/meta/TEST_group_*.csv\")):  # ex: test/meta/TEST_group_09.csv\n",
    "    wid = os.path.splitext(os.path.basename(gp))[0].split(\"_\")[-1]  # \"00\" ~ \"09\"\n",
    "    fid = f\"TEST_{wid}\"  # TEST_00 …\n",
    "\n",
    "    g = _read_csv_robust(gp).rename(columns={\"영업일자\": DATE})\n",
    "    g[DATE] = to_datetime_norm(g[DATE])\n",
    "\n",
    "    # 겨울 시즌 피처 생성\n",
    "    g[\"month\"] = g[DATE].dt.month\n",
    "    g[\"is_ski_season\"] = g[\"month\"].isin([12,1,2]).astype(int)\n",
    "\n",
    "    season_mask = g[\"is_ski_season\"] == 1\n",
    "    if season_mask.any():\n",
    "        season_start = g.loc[season_mask, DATE].min()\n",
    "        season_end   = g.loc[season_mask, DATE].max()\n",
    "        season_len   = (season_end - season_start).days + 1\n",
    "        g[\"day_of_season\"] = (\n",
    "            (g[DATE] - season_start).dt.days / season_len\n",
    "        ).where(season_mask, 0.0)\n",
    "    else:\n",
    "        g[\"day_of_season\"] = 0.0\n",
    "\n",
    "    # 필요한 컬럼만 저장\n",
    "    test_group[fid] = g[[DATE, \"is_ski_season\", \"day_of_season\"]]\n",
    "\n",
    "# fallback (merge 실패 시 빈 df 반환용)\n",
    "_group_fallback = pd.DataFrame({DATE: pd.to_datetime([]),\n",
    "                                \"is_ski_season\": [],\n",
    "                                \"day_of_season\": []})\n",
    "\n",
    "def add_group_feats(df, gday):\n",
    "    return df.merge(gday, on=DATE, how=\"left\")\n",
    "\n",
    "test_group1 = {}\n",
    "\n",
    "for gp in sorted(glob.glob(\"test/meta/TEST_group_*.csv\")):  \n",
    "    wid = os.path.splitext(os.path.basename(gp))[0].split(\"_\")[-1]  \n",
    "    fid = f\"TEST_{wid}\"\n",
    "\n",
    "    g = _read_csv_robust(gp).rename(columns={\"영업일자\": DATE})\n",
    "    g[DATE] = pd.to_datetime(g[DATE]).dt.normalize()\n",
    "\n",
    "    # 카페테리아 + 포레스트릿 합산\n",
    "    col_a = next(c for c in g.columns if \"카페테리아\" in c)\n",
    "    col_b = next(c for c in g.columns if \"포레스트릿\" in c)\n",
    "    g[\"cf_sum\"] = g[col_a] + g[col_b]\n",
    "\n",
    "    # 이진화\n",
    "    g[\"is_forest_event\"] = (g[\"cf_sum\"] > 0).astype(int)\n",
    "\n",
    "    # dict에 저장\n",
    "    test_group1[fid] = g[[DATE, \"is_forest_event\"]]\n",
    "\n",
    "_group_fallback_2 = pd.DataFrame({\n",
    "    DATE: pd.to_datetime([]),\n",
    "    \"is_forest_event\": []\n",
    "})\n",
    "\n",
    "def add_group_feats(df, gday):\n",
    "    return df.merge(gday, on=DATE, how=\"left\")\n",
    "    \n",
    "# ==== 추가 끝 ====\n",
    "\n",
    "def build_feats(df_in):\n",
    "    f = df_in.copy()\n",
    "    f = f.sort_values([KEY, DATE])\n",
    "    f[\"month\"] = f[DATE].dt.month\n",
    "    f[\"dayofweek\"] = f[DATE].dt.dayofweek\n",
    "    f[\"day\"] = f[DATE].dt.day\n",
    "    f[\"dayofyear\"] = f[DATE].dt.dayofyear\n",
    "    f[\"is_month_end\"] = f[DATE].dt.is_month_end.astype(int)\n",
    "    f[\"is_quarter_end\"] = f[DATE].dt.is_quarter_end.astype(int)\n",
    "    f[\"is_weekend\"] = (f[\"dayofweek\"]>=5).astype(int)\n",
    "\n",
    "    for h in range(1, PREDICT+1):\n",
    "        dth = f[DATE] + pd.to_timedelta(h, unit=\"D\")\n",
    "        f[f\"dow_h{h}\"] = dth.dt.dayofweek\n",
    "        f[f\"is_weekend_h{h}\"] = (f[f\"dow_h{h}\"]>=5).astype(int)\n",
    "        f[f\"is_wkhol_h{h}\"] = dth.isin(pd.DatetimeIndex(HOL_WEEKDAY_SET)).astype(int)\n",
    "\n",
    "    for lag in [7,14,21]: f[f\"lag_{lag}\"] = f.groupby(KEY)[TARGET].shift(lag)\n",
    "    for lag in [1,2,3,4,5,6]: f[f\"lag_{lag}\"] = f.groupby(KEY)[TARGET].shift(lag)\n",
    "    for w in [7,14]:\n",
    "        f[f\"rolling_mean_{w}\"]   = f.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(w).mean())\n",
    "        f[f\"rolling_std_{w}\"]    = f.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(w).std())\n",
    "        f[f\"rolling_median_{w}\"] = f.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(w).median())\n",
    "    f[\"rolling_mean_21\"] = f.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(21).mean())\n",
    "    f[\"ratio_mean7_21\"]  = f[\"rolling_mean_7\"]/f[\"rolling_mean_21\"]\n",
    "    f[\"ratio_mean14_21\"] = f[\"rolling_mean_14\"]/f[\"rolling_mean_21\"]\n",
    "\n",
    "    def _slope(v):\n",
    "        v = v[np.isfinite(v)]\n",
    "        if v.size < 2: return np.nan\n",
    "        x = np.arange(v.size, dtype=float)\n",
    "        xm, ym = x.mean(), v.mean()\n",
    "        denom = ((x-xm)**2).sum()\n",
    "        return 0.0 if denom==0 else float(((x-xm)*(v-ym)).sum()/denom)\n",
    "\n",
    "    f[\"slope_7\"]  = f.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(7).apply(_slope, raw=True))\n",
    "    f[\"slope_14\"] = f.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).rolling(14).apply(_slope, raw=True))\n",
    "    f[\"ewm_mean_7\"] = f.groupby(KEY)[TARGET].transform(lambda x: x.shift(1).ewm(span=7, adjust=False, min_periods=2).mean())\n",
    "    x_dow = f[\"dayofweek\"].astype(float)\n",
    "    f[\"dow_sin\"] = np.sin(2*np.pi*x_dow/7.0); f[\"dow_cos\"] = np.cos(2*np.pi*x_dow/7.0)\n",
    "    f[\"key_encoded\"] = f[KEY].astype(str).map(key2id).astype(\"category\")\n",
    "\n",
    "    def _flag_lzb_local(g):\n",
    "        iz = (g[TARGET]==0).astype(int)\n",
    "        bid = (iz != iz.shift()).cumsum()\n",
    "        blen = iz.groupby(bid).transform(\"sum\")\n",
    "        return ((iz==1) & (blen >= NON_SELLING_MIN_DAYS)).astype(int)\n",
    "    f[\"is_long_zero_block\"] = f.groupby(KEY, sort=False).apply(_flag_lzb_local).reset_index(level=0, drop=True).astype(int)\n",
    "    return f\n",
    "\n",
    "# === 앵커 앙상블 + p 앙상블 동시 적용 ===\n",
    "all_preds = []\n",
    "for path in test_files:\n",
    "    fid = os.path.splitext(os.path.basename(path))[0]\n",
    "    tdf = _read_csv_robust(path)\n",
    "    tdf[DATE] = to_datetime_norm(tdf[DATE])\n",
    "    tdf = tdf.sort_values([KEY, DATE]).reset_index(drop=True)\n",
    "\n",
    "    tdf_imp  = weekday_holiday_impute(tdf, HOL_WEEKDAY_SET)\n",
    "    tdf_safe = spike_clamp(tdf_imp, HOL_WEEKDAY_SET)\n",
    "    tdf_safe = add_weather_feats(tdf_safe, test_wday.get(fid, _w_fallback))\n",
    "    tdf_safe = add_room_feats(tdf_safe, test_room.get(fid, _room_fallback))\n",
    "    tdf_safe = add_group_feats(tdf_safe, test_group.get(fid, _group_fallback))\n",
    "    tdf_safe = add_group_feats(tdf_safe, test_group1.get(fid, _group_fallback_2))\n",
    "    \n",
    "    his = tdf_safe.sort_values([KEY, DATE])\n",
    "    last_date = his[DATE].max()\n",
    "    date_set = set(his[DATE])\n",
    "    anchors = sorted(d for d in (last_date - pd.to_timedelta(np.arange(ANCHOR_K_FULL), \"D\")) if d in date_set)\n",
    "\n",
    "    bucket = {}\n",
    "    for ad in anchors:\n",
    "        sub = his[his[DATE] <= ad].copy()\n",
    "        Feat = build_feats(sub)\n",
    "        rowA = Feat[Feat[DATE]==ad].copy()\n",
    "        if rowA.empty: \n",
    "            continue\n",
    "        Xrow = rowA[feat_cols].copy()\n",
    "        for c in (\"key_encoded\",\"month\",\"dayofweek\"):\n",
    "            if c in Xrow.columns: Xrow[c] = Xrow[c].astype(\"category\")\n",
    "\n",
    "        # p-가중 앙상블 예측\n",
    "        Y_mix = None\n",
    "        for p, mdl in models_full.items():\n",
    "            Yp = mdl.predict(Xrow)  # (n_keys, 7)\n",
    "            w  = P_WEIGHTS.get(p, 0.0)\n",
    "            Y_mix = (w*Yp) if Y_mix is None else (Y_mix + w*Yp)\n",
    "\n",
    "        meta = rowA[[KEY,DATE]].reset_index(drop=True)\n",
    "        for i in range(len(meta)):\n",
    "            keyi = meta.at[i, KEY]\n",
    "            for h in range(PREDICT):\n",
    "                dtp = (ad + pd.Timedelta(days=h+1)).normalize()\n",
    "                bucket.setdefault((dtp, keyi), []).append(float(Y_mix[i, h]))\n",
    "\n",
    "    for (dtp, keyi), vals in bucket.items():\n",
    "        all_preds.append({DATE: dtp, KEY: keyi, TARGET: float(np.mean(vals))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efc3bf36",
   "metadata": {
    "id": "efc3bf36"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>key_encoded</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>is_quarter_end</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>rolling_mean_7</th>\n",
       "      <th>rolling_std_7</th>\n",
       "      <th>...</th>\n",
       "      <th>is_wkhol_h4</th>\n",
       "      <th>dow_h5</th>\n",
       "      <th>is_weekend_h5</th>\n",
       "      <th>is_wkhol_h5</th>\n",
       "      <th>dow_h6</th>\n",
       "      <th>is_weekend_h6</th>\n",
       "      <th>is_wkhol_h6</th>\n",
       "      <th>dow_h7</th>\n",
       "      <th>is_weekend_h7</th>\n",
       "      <th>is_wkhol_h7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>5.094348</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.142857</td>\n",
       "      <td>45.772730</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.428571</td>\n",
       "      <td>4.961759</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.428571</td>\n",
       "      <td>4.314979</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.133893</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>162</td>\n",
       "      <td>24</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.142857</td>\n",
       "      <td>20.497387</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4591</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>163</td>\n",
       "      <td>24</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>24.812631</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4619</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>164</td>\n",
       "      <td>24</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>48.016366</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4647</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>165</td>\n",
       "      <td>24</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.142857</td>\n",
       "      <td>13.716518</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>24</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>30.424771</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month dayofweek key_encoded  day  dayofyear  is_month_end  \\\n",
       "27       5         5           0   24        144             0   \n",
       "55       5         5           1   24        144             0   \n",
       "83       5         5           2   24        144             0   \n",
       "111      5         5           3   24        144             0   \n",
       "139      5         5           4   24        144             0   \n",
       "...    ...       ...         ...  ...        ...           ...   \n",
       "4563     5         5         162   24        144             0   \n",
       "4591     5         5         163   24        144             0   \n",
       "4619     5         5         164   24        144             0   \n",
       "4647     5         5         165   24        144             0   \n",
       "4675     5         5         166   24        144             0   \n",
       "\n",
       "      is_quarter_end  is_weekend  rolling_mean_7  rolling_std_7  ...  \\\n",
       "27                 0           1        3.571429       5.094348  ...   \n",
       "55                 0           1       40.142857      45.772730  ...   \n",
       "83                 0           1        5.428571       4.961759  ...   \n",
       "111                0           1        2.428571       4.314979  ...   \n",
       "139                0           1        0.428571       1.133893  ...   \n",
       "...              ...         ...             ...            ...  ...   \n",
       "4563               0           1       29.142857      20.497387  ...   \n",
       "4591               0           1       31.000000      24.812631  ...   \n",
       "4619               0           1       85.714286      48.016366  ...   \n",
       "4647               0           1       22.142857      13.716518  ...   \n",
       "4675               0           1       36.000000      30.424771  ...   \n",
       "\n",
       "      is_wkhol_h4  dow_h5  is_weekend_h5  is_wkhol_h5  dow_h6  is_weekend_h6  \\\n",
       "27              0       3              0            0       4              0   \n",
       "55              0       3              0            0       4              0   \n",
       "83              0       3              0            0       4              0   \n",
       "111             0       3              0            0       4              0   \n",
       "139             0       3              0            0       4              0   \n",
       "...           ...     ...            ...          ...     ...            ...   \n",
       "4563            0       3              0            0       4              0   \n",
       "4591            0       3              0            0       4              0   \n",
       "4619            0       3              0            0       4              0   \n",
       "4647            0       3              0            0       4              0   \n",
       "4675            0       3              0            0       4              0   \n",
       "\n",
       "      is_wkhol_h6  dow_h7  is_weekend_h7  is_wkhol_h7  \n",
       "27              0       5              1            0  \n",
       "55              0       5              1            0  \n",
       "83              0       5              1            0  \n",
       "111             0       5              1            0  \n",
       "139             0       5              1            0  \n",
       "...           ...     ...            ...          ...  \n",
       "4563            0       5              1            0  \n",
       "4591            0       5              1            0  \n",
       "4619            0       5              1            0  \n",
       "4647            0       5              1            0  \n",
       "4675            0       5              1            0  \n",
       "\n",
       "[167 rows x 59 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PxkD6_-GHtKu",
   "metadata": {
    "id": "PxkD6_-GHtKu"
   },
   "source": [
    "## 7. 후처리(Metric-aware A+B, 라운딩, min-1 규칙)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "981b560e",
   "metadata": {
    "id": "981b560e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postprocessed rows: 21710\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영업일자</th>\n",
       "      <th>영업장명_메뉴명</th>\n",
       "      <th>매출수량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-08</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-07-09</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-07-10</td>\n",
       "      <td>느티나무 셀프BBQ_1인 수저세트</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        영업일자            영업장명_메뉴명  매출수량\n",
       "0 2024-07-08  느티나무 셀프BBQ_1인 수저세트     1\n",
       "1 2024-07-09  느티나무 셀프BBQ_1인 수저세트     2\n",
       "2 2024-07-10  느티나무 셀프BBQ_1인 수저세트     3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === [대체 셀] 기존 후처리 로직 중 '블록 통계 소스' 불일치만 수정 (tdf_safe 기준으로 재계산) ===\n",
    "\n",
    "sub_long = pd.DataFrame(all_preds).copy()\n",
    "sub_long[DATE] = to_datetime_norm(sub_long[DATE])\n",
    "\n",
    "# 파일별 블록 통계 수집: 예측 단계와 동일한 안전 전처리(tdf_safe) 기준으로 pos/length/weekend_mean 산출\n",
    "date_to_file, block_pos_values, block_lengths, weekend_means = {}, {}, {}, {}\n",
    "for p in test_files:\n",
    "    fid = os.path.basename(p).split(\".\")[0]\n",
    "    try:\n",
    "        dfb = pd.read_csv(p)\n",
    "    except UnicodeDecodeError:\n",
    "        dfb = pd.read_csv(p, encoding=\"cp949\")\n",
    "    dfb[DATE] = to_datetime_norm(dfb[DATE])\n",
    "    dfb = dfb.sort_values([KEY, DATE]).reset_index(drop=True)\n",
    "\n",
    "    # (A) 평일 공휴일 imputing  [예측 단계와 동일]\n",
    "    xx = dfb.copy()\n",
    "    xx[\"dow\"] = xx[DATE].dt.dayofweek\n",
    "    xx[\"is_weekday\"] = (xx[\"dow\"] < 5).astype(int)\n",
    "    xx[\"is_weekday_hol\"] = xx[DATE].isin(HOL_WEEKDAY_SET).astype(int)\n",
    "    outs = []\n",
    "    for key_i, g in xx.groupby(KEY, sort=False):\n",
    "        g = g.sort_values(DATE).copy()\n",
    "        end_date = g[DATE].max()\n",
    "        cand_all = g[(g[\"is_weekday\"] == 1) & (g[\"is_weekday_hol\"] == 0)].copy()\n",
    "        all_weekday_zero = (cand_all[TARGET].sum() == 0)\n",
    "        cand = cand_all\n",
    "        for idx, row in g.iterrows():\n",
    "            if not (row[\"is_weekday\"] == 1 and row[\"is_weekday_hol\"] == 1):\n",
    "                continue\n",
    "            if all_weekday_zero:\n",
    "                g.at[idx, TARGET] = 0\n",
    "                continue\n",
    "            dow_h = int(row[\"dow\"]); date_h = row[DATE]\n",
    "            pool_dow = cand[cand[\"dow\"] == dow_h]\n",
    "            def _wmean(vals, dates, end_date, decay=0.90, lastweek_window=7, boost=0.50):\n",
    "                if len(vals) == 0: return np.nan\n",
    "                vals = np.asarray(vals, float); dates = pd.to_datetime(dates)\n",
    "                delta = (end_date - dates).days.astype(float)\n",
    "                w = (decay ** delta)\n",
    "                w = np.where(dates >= (end_date - pd.Timedelta(days=lastweek_window-1)), w*(1.0+boost), w)\n",
    "                w = np.clip(w, 1e-6, None)\n",
    "                return float(np.sum(w*vals) / np.sum(w))\n",
    "            base = _wmean(pool_dow[TARGET].values, pool_dow[DATE].values, end_date=end_date) if len(pool_dow) >= 1 \\\n",
    "                   else _wmean(cand[TARGET].values, cand[DATE].values, end_date=end_date)\n",
    "            t7 = date_h - pd.Timedelta(days=7)\n",
    "            prev = g[(g[DATE] == t7) & (g[\"is_weekday\"] == 1) & (g[\"is_weekday_hol\"] == 0)]\n",
    "            val_t7 = float(prev[TARGET].iloc[0]) if len(prev) == 1 else np.nan\n",
    "            if np.isfinite(base):\n",
    "                y_hat = base if not np.isfinite(val_t7) else 0.65*base + 0.35*val_t7\n",
    "                g.at[idx, TARGET] = int(max(0, round(y_hat)))\n",
    "            else:\n",
    "                g.at[idx, TARGET] = 0\n",
    "        outs.append(g)\n",
    "    tdf_imp_stat = pd.concat(outs, axis=0).drop(columns=[\"dow\",\"is_weekday\",\"is_weekday_hol\"])\n",
    "\n",
    "    # (B) 급등 클램프  [예측 단계와 동일]\n",
    "    x2 = tdf_imp_stat.copy()\n",
    "    x2[\"dow\"] = x2[DATE].dt.dayofweek\n",
    "    x2[\"is_nonhol_weekday\"] = ((x2[\"dow\"] < 5) & (~x2[DATE].isin(HOL_WEEKDAY_SET))).astype(int)\n",
    "    x2[\"is_hol_wk\"] = (x2[DATE].isin(HOL_WEEKDAY_SET)).astype(int)\n",
    "    outs = []\n",
    "    for k_i, g in x2.groupby(KEY, sort=False):\n",
    "        if (BRUNCH_WD in str(k_i)) or (BRUNCH_WE in str(k_i)):\n",
    "            outs.append(g); continue\n",
    "        g = g.copy()\n",
    "        g[\"med_wd_dow\"] = np.nan\n",
    "        for d in range(5):\n",
    "            idx = (g[\"dow\"] == d) & (g[\"is_nonhol_weekday\"] == 1)\n",
    "            s = g.loc[idx, TARGET].astype(float)\n",
    "            med = s.shift(1).rolling(window=4, min_periods=2).median()\n",
    "            g.loc[idx, \"med_wd_dow\"] = med.values\n",
    "        is_metric_target = ((\"단체\" in str(k_i)) or (str(k_i) in EXTRA_GROUP_KEYS))\n",
    "        if is_metric_target:\n",
    "            thr_up = (1.0 + 0.25) * g[\"med_wd_dow\"]\n",
    "            adj = ((g[\"is_hol_wk\"] == 1) & np.isfinite(g[\"med_wd_dow\"]) & (g[TARGET] > thr_up))\n",
    "            g.loc[adj, TARGET] = np.maximum(0.0, np.round((1.0 + 0.10) * g.loc[adj, \"med_wd_dow\"]))\n",
    "        g = g.drop(columns=[\"med_wd_dow\"])\n",
    "        outs.append(g)\n",
    "    tdf_safe_stat = pd.concat(outs, axis=0).drop(columns=[\"dow\",\"is_nonhol_weekday\",\"is_hol_wk\"]).sort_values([KEY, DATE])\n",
    "\n",
    "    # tdf_safe 기준 통계\n",
    "    last = tdf_safe_stat[DATE].max()\n",
    "    for h in range(1, PREDICT+1):\n",
    "        date_to_file[(last + pd.Timedelta(days=h)).strftime(\"%Y-%m-%d\")] = fid\n",
    "    for k_i, g in tdf_safe_stat.groupby(KEY):\n",
    "        g = g.sort_values(DATE)\n",
    "        pos = g.loc[g[TARGET] > 0, TARGET].astype(float).values\n",
    "        block_pos_values[(fid, k_i)] = pos\n",
    "        block_lengths[(fid, k_i)] = int(g.shape[0])\n",
    "        wknd = g[g[DATE].dt.dayofweek >= 5][TARGET].astype(float)\n",
    "        weekend_means[(fid, k_i)] = float(wknd.mean()) if wknd.size > 0 else np.nan\n",
    "\n",
    "# (A) 평일 공휴일이면 주말 평균으로 대체  [변경 없음]\n",
    "if APPLY_METRIC_AWARE_WK_HOLOV:\n",
    "    rows = []\n",
    "    for _, r in sub_long.iterrows():\n",
    "        dt = r[DATE]\n",
    "        if (dt.weekday() < 5) and (dt in HOL_WEEKDAY_SET):\n",
    "            fid = date_to_file.get(dt.strftime(\"%Y-%m-%d\"))\n",
    "            wk = weekend_means.get((fid, r[KEY])) if fid is not None else np.nan\n",
    "            val = float(wk) if np.isfinite(wk) else float(r[TARGET])\n",
    "        else:\n",
    "            val = float(r[TARGET])\n",
    "        rows.append(val)\n",
    "    sub_long[TARGET] = np.array(rows, dtype=float)\n",
    "\n",
    "# (B) weighted-SMAPE 블렌딩  [변경 없음]\n",
    "def is_metric_target_post(k):\n",
    "    s = str(k)\n",
    "    if \"공깃밥\" in s: return False\n",
    "    if (BRUNCH_WD in s) or (BRUNCH_WE in s): return False\n",
    "    if \"단체\" in s: return True\n",
    "    return s in EXTRA_GROUP_KEYS\n",
    "\n",
    "def _weighted_smape_constant(pos_vals, n_days, decay=0.92, clamp_k=0.50, beta_soft=0.50):\n",
    "    pos = np.asarray(pos_vals, float)\n",
    "    if pos.size == 0: return 1, 0.0\n",
    "    pos = np.sort(pos); q1,q2,q3 = np.percentile(pos,[25,50,75]); iqr = q3-q1; p95 = np.percentile(pos,95)\n",
    "    w = np.array([decay**(pos.size-1-i) for i in range(pos.size)], float); w /= w.sum()\n",
    "    base_cands = np.unique(np.round(np.r_[pos,q1,q2,q3,(q1+q3)/2,p95]).astype(int))\n",
    "    lo = max(1, int(np.floor(max(1, q1 - clamp_k*iqr)))); hi = int(np.ceil(min(max(base_cands.max(),2), p95*1.10)))\n",
    "    cands = np.unique(np.r_[base_cands, np.arange(lo, max(lo+1, hi+1))])\n",
    "    def _wsmape(c): c=float(c); return np.sum(w*(2.0*np.abs(c-pos)/(np.abs(c)+pos)))\n",
    "    scores = np.array([_wsmape(c) for c in cands]); c_star = int(cands[np.argmin(scores)])\n",
    "    clamp_lo = max(1, int(np.floor(q1 - clamp_k*iqr))); clamp_hi = int(np.ceil(q3 + clamp_k*iqr))\n",
    "    c_clip = int(np.clip(c_star, clamp_lo, clamp_hi))\n",
    "    c_final = int(np.round((1 - beta_soft)*c_star + beta_soft*c_clip)); c_final = max(1, c_final)\n",
    "    zero_rate = 1.0 - (pos.size / max(1, n_days))\n",
    "    iqr_ratio = (iqr / (q2 + 1e-9)) if q2 > 0 else 0.0; iqr_ratio = float(np.clip(iqr_ratio, 0.0, 2.0))\n",
    "    alpha_raw = 0.6*zero_rate + 0.4*(iqr_ratio / (1.0 + iqr_ratio))\n",
    "    alpha = float(np.clip(alpha_raw, 0.0, 0.5))\n",
    "    return c_final, alpha\n",
    "\n",
    "if APPLY_METRIC_AWARE_WSMAPE:\n",
    "    new_vals = []\n",
    "    for _, r in sub_long.iterrows():\n",
    "        k = r[KEY]\n",
    "        if not is_metric_target_post(k):\n",
    "            new_vals.append(float(r[TARGET])); continue\n",
    "        fid = date_to_file.get(r[DATE].strftime(\"%Y-%m-%d\"))\n",
    "        if fid is None:\n",
    "            new_vals.append(float(r[TARGET])); continue\n",
    "        pos = block_pos_values.get((fid, k), np.array([]))\n",
    "        nd  = block_lengths.get((fid, k), INPUT_WINDOW_DAYS)\n",
    "        c, a = _weighted_smape_constant(pos, nd)\n",
    "        y = float(r[TARGET]); y_new = (1.0 - a)*y + a*float(c)\n",
    "        new_vals.append(y_new)\n",
    "    sub_long[TARGET] = np.array(new_vals, dtype=float)\n",
    "\n",
    "# 라운딩 임계값은 그대로 유지\n",
    "ths = np.round(np.arange(0.25, 0.351, 0.01), 3)\n",
    "best_thr = 0.130\n",
    "sub_long[TARGET] = round_nonneg(sub_long[TARGET].values, best_thr).astype(int)\n",
    "\n",
    "# 활성 키 min-1  [변경 없음]\n",
    "if FORCE_ACTIVE_MIN1 or FORCE_GLOBAL_MIN1:\n",
    "    if FORCE_ACTIVE_MIN1:\n",
    "        upd = []\n",
    "        for _, r in sub_long.iterrows():\n",
    "            y = int(r[TARGET])\n",
    "            fid = date_to_file.get(r[DATE].strftime(\"%Y-%m-%d\"))\n",
    "            if (y == 0) and (fid is not None) and is_metric_target_post(r[KEY]):\n",
    "                pos = block_pos_values.get((fid, r[KEY]), np.array([]))\n",
    "                if pos.size > 0: y = 1\n",
    "            upd.append(y)\n",
    "        sub_long[TARGET] = np.array(upd, dtype=int)\n",
    "    if FORCE_GLOBAL_MIN1:\n",
    "        sub_long.loc[sub_long[TARGET] == 0, TARGET] = 1\n",
    "\n",
    "print(\"postprocessed rows:\", len(sub_long))\n",
    "sub_long.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mbyrl6t9HtKw",
   "metadata": {
    "id": "mbyrl6t9HtKw"
   },
   "source": [
    "## 8. 제출 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ybV1EiYcHtKx",
   "metadata": {
    "id": "ybV1EiYcHtKx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVE] -> Pipeline_1_we_PEsemble_cs3.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영업일자</th>\n",
       "      <th>느티나무 셀프BBQ_1인 수저세트</th>\n",
       "      <th>느티나무 셀프BBQ_BBQ55(단체)</th>\n",
       "      <th>느티나무 셀프BBQ_대여료 30,000원</th>\n",
       "      <th>느티나무 셀프BBQ_대여료 60,000원</th>\n",
       "      <th>느티나무 셀프BBQ_대여료 90,000원</th>\n",
       "      <th>느티나무 셀프BBQ_스프라이트 (단체)</th>\n",
       "      <th>느티나무 셀프BBQ_신라면</th>\n",
       "      <th>느티나무 셀프BBQ_쌈장</th>\n",
       "      <th>느티나무 셀프BBQ_육개장 사발면</th>\n",
       "      <th>...</th>\n",
       "      <th>화담숲주막_스프라이트</th>\n",
       "      <th>화담숲주막_참살이 막걸리</th>\n",
       "      <th>화담숲주막_찹쌀식혜</th>\n",
       "      <th>화담숲주막_콜라</th>\n",
       "      <th>화담숲주막_해물파전</th>\n",
       "      <th>화담숲카페_메밀미숫가루</th>\n",
       "      <th>화담숲카페_아메리카노 HOT</th>\n",
       "      <th>화담숲카페_아메리카노 ICE</th>\n",
       "      <th>화담숲카페_카페라떼 ICE</th>\n",
       "      <th>화담숲카페_현미뻥스크림</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00+1일</td>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00+2일</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00+3일</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00+4일</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00+5일</td>\n",
       "      <td>6</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         영업일자  느티나무 셀프BBQ_1인 수저세트  느티나무 셀프BBQ_BBQ55(단체)  \\\n",
       "0  TEST_00+1일                   6                    56   \n",
       "1  TEST_00+2일                   1                    58   \n",
       "2  TEST_00+3일                   3                    60   \n",
       "3  TEST_00+4일                   4                    60   \n",
       "4  TEST_00+5일                   6                    63   \n",
       "\n",
       "   느티나무 셀프BBQ_대여료 30,000원  느티나무 셀프BBQ_대여료 60,000원  느티나무 셀프BBQ_대여료 90,000원  \\\n",
       "0                       6                       3                       1   \n",
       "1                       1                       1                       1   \n",
       "2                       2                       1                       1   \n",
       "3                       2                       1                       1   \n",
       "4                       3                       2                       1   \n",
       "\n",
       "   느티나무 셀프BBQ_스프라이트 (단체)  느티나무 셀프BBQ_신라면  느티나무 셀프BBQ_쌈장  느티나무 셀프BBQ_육개장 사발면  \\\n",
       "0                     14               2              1                   1   \n",
       "1                     15               1              1                   1   \n",
       "2                     15               1              1                   1   \n",
       "3                     16               1              1                   1   \n",
       "4                     18               2              1                   1   \n",
       "\n",
       "   ...  화담숲주막_스프라이트  화담숲주막_참살이 막걸리  화담숲주막_찹쌀식혜  화담숲주막_콜라  화담숲주막_해물파전  \\\n",
       "0  ...            5             12          12         4          46   \n",
       "1  ...            1              1           1         1           1   \n",
       "2  ...            3              5           5         2          17   \n",
       "3  ...            2              4           5         2          16   \n",
       "4  ...            2              5           6         2          16   \n",
       "\n",
       "   화담숲카페_메밀미숫가루  화담숲카페_아메리카노 HOT  화담숲카페_아메리카노 ICE  화담숲카페_카페라떼 ICE  \\\n",
       "0            20                5               22               6   \n",
       "1             1                1                1               1   \n",
       "2            10                3               11               4   \n",
       "3             9                3               11               3   \n",
       "4            12                3               15               5   \n",
       "\n",
       "   화담숲카페_현미뻥스크림  \n",
       "0            10  \n",
       "1             1  \n",
       "2             3  \n",
       "3             3  \n",
       "4             4  \n",
       "\n",
       "[5 rows x 168 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUT_PATH = \"Pipeline_1_we_PEsemble_cs3.csv\"\n",
    "\n",
    "# sample 형식에 맞춰 pivot\n",
    "sample = pd.read_csv(\"sample_submission.csv\", engine=\"python\")\n",
    "label_col = sample.columns[0]\n",
    "\n",
    "# date_label 매핑: \"TEST_xx+Nd\"\n",
    "date_label = {}\n",
    "for fp in test_files:\n",
    "    tdf = pd.read_csv(fp)\n",
    "    tdf[DATE] = to_datetime_norm(tdf[DATE])\n",
    "    fid = os.path.basename(fp).split(\".\")[0]\n",
    "    last = tdf[DATE].max()\n",
    "    for i in range(PREDICT):\n",
    "        date_label[(last + pd.Timedelta(days=i+1)).strftime(\"%Y-%m-%d\")] = f\"{fid}+{i+1}일\"\n",
    "\n",
    "sub_long = sub_long.copy()\n",
    "sub_long[\"date_label\"] = sub_long[DATE].dt.strftime(\"%Y-%m-%d\").map(date_label)\n",
    "\n",
    "pivot = sub_long.pivot_table(index=\"date_label\", columns=KEY, values=TARGET, aggfunc=\"first\")\n",
    "final = sample.set_index(label_col)\n",
    "common = [c for c in final.columns if c in pivot.columns]\n",
    "if len(common)>0:\n",
    "    final[common] = final[common].combine_first(pivot[common])\n",
    "    final.update(pivot[common])\n",
    "\n",
    "final = final.fillna(1).astype(np.int64).reset_index()\n",
    "final.columns = sample.columns\n",
    "\n",
    "final.to_csv(OUT_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"[SAVE] ->\", OUT_PATH)\n",
    "final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2eb7a24",
   "metadata": {
    "id": "e2eb7a24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 168)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V5E1",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
